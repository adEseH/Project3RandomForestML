{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some libraries and the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_halving_search_cv # because it is experimental we need this\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "from ISLP import load_data, confusion_table\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, log_loss, mean_squared_error,confusion_matrix, classification_report,balanced_accuracy_score, max_error, PredictionErrorDisplay,mean_absolute_error, mean_absolute_percentage_error)\n",
    "from sklearn.ensemble import (RandomForestRegressor, RandomForestClassifier)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image, Markdown\n",
    "import graphviz\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statistics\n",
    "import re\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no idea what this is\n",
    "# main dataset\n",
    "data_index_2 = pd.read_csv('../Project_datasets/data_index_2.csv', quotechar=\"'\")\n",
    "data_index_2 = data_index_2.drop(columns=['Unnamed: 0'])\n",
    "nan_template = ~(data_index_2.isna().any(axis=1))\n",
    "data_index_2 = data_index_2[nan_template] # delete rows with NaN\n",
    "# precipitation by day and statistics\n",
    "if True:\n",
    "    Predaymean = pd.read_csv('../Project_datasets/Predaymean1961_1990.csv')[nan_template]\n",
    "    Predaymean_statistics = pd.read_csv('../Project_datasets/Predaymean1961_1990_statics.csv')[nan_template]\n",
    "    # maximum temperature by day and statistics\n",
    "    Tmaxdaymean = pd.read_csv('../Project_datasets/Tmaxdaymean1961_1990.csv')[nan_template]\n",
    "    Tmaxdaymean_statistics = pd.read_csv('../Project_datasets/Tmaxdaymean1961_1990_statics.csv')[nan_template]\n",
    "    # minimum temperature by day and statistics\n",
    "    Tmindaymean = pd.read_csv('../Project_datasets/Tmindaymean1961_1990.csv')[nan_template]\n",
    "    Tmindaymean_statistics = pd.read_csv('../Project_datasets/Tmindaymean1961_1990_statics.csv')[nan_template]\n",
    "    # mean temperature by day and statistics\n",
    "    Tmpdaymean = pd.read_csv('../Project_datasets/Tmpdaymean1961_1990.csv')[nan_template]\n",
    "    Tmpdaymean_statistics = pd.read_csv('../Project_datasets/Tmpdaymean1961_1990_statics.csv')[nan_template]\n",
    "    # shortwave radiation flux\n",
    "    Tswrfdaymean = pd.read_csv('../Project_datasets/Tswrfdaymean1961_1990.csv')[nan_template]\n",
    "    Tswrfdaymean_statistics = pd.read_csv('../Project_datasets/Tswrfdaymean1961_1990_statics.csv')[nan_template]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridlist_pan_gfed_ISO3_UN = open('../Project_datasets/gridlist_pan_gfed_ISO3_UN.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short legend about the colums: \n",
    "\n",
    "Lon: Longitude<br>\n",
    "Lat: Latidude\n",
    "\n",
    "stuff about the souil texture: <br>\n",
    "\n",
    "clay: Clay in %<br>\n",
    "silt: Silt in % (sedimentary deposit that is formed when a river deposits the material it is carrying)<br>\n",
    "slay: slay in %(soil in eg. rainforest) <br>\n",
    "sand: sand in % %<br>\n",
    "orC: organic carbondioxid in %<br>\n",
    "CN: Cyanide in %<br>\n",
    "pH: pH<br>\n",
    "cell fraction: portion of cells / organic material in soil in % <br>\n",
    "\n",
    "\n",
    "Allways with season: Same as the tables below.\n",
    "\n",
    "tmax: maximum temperatur in K <br>\n",
    "tmin: min temperature in K <br>\n",
    "tmp:mean temperature in K <br>\n",
    "Pre: Precipitation, mm day-1 <br>\n",
    "tswrf: Total shortwave radiation flux, W m-2\n",
    "\n",
    "\n",
    "This is the GUESS output: \n",
    "\n",
    "NPP: net primary productivity (kg C m-2 year-1)<br>\n",
    "SoilR: soil respiration (kg C m-2 year-1)<br>\n",
    "MaxBiomeCmass: The maximum biomass from a single biome (kg C m-2)<br>\n",
    "MxbiomeLAI: The maximum leaf area index from a single biome (unitless)<br>\n",
    "VegC: Vegetation carbon poo (kg C m-2)l<br>\n",
    "LitterC: Litter carbon pool (kg C m-2)<br>\n",
    "SoilC: Soil carbon pool (kg C m-2)<br>\n",
    "Biome_Cmass: The biome type based on the maximum biomass (category)<br>\n",
    "Biome_LAI: The biome type based on the maximum LAI (category)<br>\n",
    "Biome_obs: The observed biome type (category)<br>\n",
    "\n",
    "Country codes\n",
    "\n",
    "GFED-region: Global Fire Emissions Database (https://www.un-spider.org/global-fire-emissions-database-gfed) <br>\n",
    "Pan_2007: Big reogion (Europa, Africa, Australia, USA, Russia, China, .... )<br>\n",
    "ISO3: Abbreviation for country <br>\n",
    "UN: Country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (59190, 83)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>sand</th>\n",
       "      <th>orgC</th>\n",
       "      <th>CN</th>\n",
       "      <th>pH</th>\n",
       "      <th>cellfraction</th>\n",
       "      <th>tmax_SpringMean</th>\n",
       "      <th>...</th>\n",
       "      <th>VegC</th>\n",
       "      <th>LitterC</th>\n",
       "      <th>SoilC</th>\n",
       "      <th>Biome_Cmax</th>\n",
       "      <th>Biome_LAI</th>\n",
       "      <th>Biome_obs</th>\n",
       "      <th>GFED-region</th>\n",
       "      <th>Pan_2007</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>UN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-179.75</td>\n",
       "      <td>71.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.020</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.482</td>\n",
       "      <td>249.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUS</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-179.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.031</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.753</td>\n",
       "      <td>250.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.015</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUS</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-179.75</td>\n",
       "      <td>68.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.031</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.447</td>\n",
       "      <td>249.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.022</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUS</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-179.75</td>\n",
       "      <td>67.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.031</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.526</td>\n",
       "      <td>250.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUS</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-179.75</td>\n",
       "      <td>67.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.031</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.422</td>\n",
       "      <td>251.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUS</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lon    Lat  clay  silt  sand   orgC    CN   pH  cellfraction  \\\n",
       "0 -179.75  71.25  0.08  0.37  0.55  0.020  11.0  5.9         0.482   \n",
       "1 -179.75  68.75  0.20  0.48  0.32  0.031  17.0  6.3         0.753   \n",
       "2 -179.75  68.25  0.20  0.48  0.32  0.031  17.0  6.3         0.447   \n",
       "3 -179.75  67.75  0.20  0.48  0.32  0.031  17.0  6.3         0.526   \n",
       "4 -179.75  67.25  0.20  0.48  0.32  0.031  17.0  6.3         0.422   \n",
       "\n",
       "   tmax_SpringMean  ...  VegC  LitterC  SoilC  Biome_Cmax  Biome_LAI  \\\n",
       "0           249.88  ...   0.0    0.000  0.000          13         13   \n",
       "1           250.64  ...   0.0    0.003  0.015          13         11   \n",
       "2           249.84  ...   0.0    0.006  0.022          13         11   \n",
       "3           250.84  ...   0.0    0.002  0.020          13         11   \n",
       "4           251.42  ...   0.0    0.003  0.016          13         11   \n",
       "\n",
       "   Biome_obs  GFED-region  Pan_2007  ISO3   UN  \n",
       "0         17           10    Russia   RUS  643  \n",
       "1         17           10    Russia   RUS  643  \n",
       "2         17           10    Russia   RUS  643  \n",
       "3         17           10    Russia   RUS  643  \n",
       "4         17           10    Russia   RUS  643  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'shape: {data_index_2.shape}')\n",
    "data_index_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"../Project_datasets/Readme.txt\",'r') as script:\n",
    "    speech = script.read().splitlines()\n",
    "\n",
    "count = 1\n",
    "for line in speech:\n",
    "    if False:\n",
    "        count+=1\n",
    "        if count % 2 == 0: #this is the remainder operator\n",
    "            print(line)\n",
    "    else:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred (Precipitation, mm day-1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Predaymean.shape}')\n",
    "#Predaymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Predaymean_statistics.shape}')\n",
    "#Predaymean_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmp (Daily mean temperature, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmpdaymean.shape}')\n",
    "#Tmpdaymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmpdaymean_statistics.shape}')\n",
    "#Tmpdaymean_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmaxdaymean.shape}')\n",
    "#Tmaxdaymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmaxdaymean_statistics.shape}')\n",
    "#Tmaxdaymean_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmindaymean.shape}')\n",
    "#Tmindaymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tmindaymean_statistics.shape}')\n",
    "#Tmindaymean_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tswrf (Total shortwave radiation flux, W m-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {Tswrfdaymean.shape}')\n",
    "#Tswrfdaymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'shape: {Tswrfdaymean_statistics.shape}')\n",
    "#Tswrfdaymean_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County List and binome legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>GFED-region</th>\n",
       "      <th>Pan_2007</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>UN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-69.75</td>\n",
       "      <td>-55.25</td>\n",
       "      <td>5</td>\n",
       "      <td>Americas</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-69.25</td>\n",
       "      <td>-55.25</td>\n",
       "      <td>5</td>\n",
       "      <td>Americas</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-71.25</td>\n",
       "      <td>-54.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Americas</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-70.75</td>\n",
       "      <td>-54.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Americas</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-70.25</td>\n",
       "      <td>-54.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Americas</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lon     Lat GFED-region  Pan_2007 ISO3   UN\n",
       "1  -69.75  -55.25           5  Americas  CHL  152\n",
       "2  -69.25  -55.25           5  Americas  CHL  152\n",
       "3  -71.25  -54.75           5  Americas  CHL  152\n",
       "4  -70.75  -54.75           5  Americas  CHL  152\n",
       "5  -70.25  -54.75           5  Americas  CHL  152"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from file into a list-of-lists table.\n",
    "with open('../Project_datasets/gridlist_pan_gfed_ISO3_UN.txt') as file:\n",
    "    datatable = [line.split() for line in file.read().splitlines()]\n",
    "\n",
    "country_codes = pd.DataFrame(datatable, columns = ['Lon', 'Lat', 'GFED-region', 'Pan_2007', 'ISO3', 'UN'] )  \n",
    "country_codes = country_codes.drop(index = 0)\n",
    "country_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Boreal decid forest\n",
      "2 Boreal ever forest\n",
      "3 Temp/boreal mix fo.\n",
      "4 Temp conifer forest\n",
      "5 Temp decid forest\n",
      "6 Temp broad ever fo.\n",
      "7 Temp mixed forest\n",
      "8 Trop season forest\n",
      "9 Trop rain forest\n",
      "10 Trop decid forest\n",
      "11 Moist savannas\n",
      "12 Dry savannas\n",
      "13 Tall grassland\n",
      "14 Dry grassland\n",
      "15 Xeric wood/shrub\n",
      "16 Arid shrub/steppe\n",
      "17 Desert\n",
      "18 Arctic/alpine tundra\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "with open(\"../Project_datasets/legend of biomes.txt\",'r') as script:\n",
    "    speech = script.read().splitlines()\n",
    "\n",
    "count = 1\n",
    "for line in speech:\n",
    "    if True:\n",
    "        count+=1\n",
    "        if count % 2 == 0: #this is the remainder operator\n",
    "            print(line)\n",
    "    else:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of samples of different biomes in different coutries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrys_sample_size = data_index_2.groupby(['ISO3', 'Biome_obs']).size()   \n",
    "#countrys_sample_size = pd.DataFrame(countrys_sample_size)\n",
    "#countrys_sample_size.columns = [ \"Size\"]           # Maybe solve later\n",
    "countrys_sample_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samply size for countries\n",
    "countrys_sample_size.at[\"EGY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and table generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names my have to be improved\n",
    "def df_to_latex(df, filename = 'mytable', caption=''):  \n",
    "    s = df.style.to_latex(\n",
    "    # column_format=\"rrrrr\",#  position=\"h\", position_float=\"centering\",\n",
    "    hrules=True,\n",
    "    multirow_align=\"t\", multicol_align=\"r\"\n",
    "    )  \n",
    "        \n",
    "    with open('../table/' + filename + '.tex', 'w') as f:\n",
    "        f.write(s)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(figure, figurename = 'my_plot'):\n",
    "    figure.savefig('../plots/' + figurename + '.pdf', bbox_inches='tight')\n",
    "\n",
    "## test\n",
    "#save_plot(fig, figurename ='worldmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot function for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics(data, name_data = 'data'):\n",
    "    \n",
    "    obs_data = \"Biome_obs\"\n",
    "    fig, ax = plt.subplots(figsize = (8,4))\n",
    "    ax = sns.countplot(data, x = obs_data)\n",
    "    save_plot(fig, figurename = 'countplot_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    obs_data = \"Biome_Cmax\"\n",
    "    fig, ax = plt.subplots(figsize = (8,4))\n",
    "    ax = sns.countplot(data, x = obs_data)\n",
    "    save_plot(fig, figurename = 'countplot_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    ## sample biomes\n",
    "    obs_data = \"Biome_obs_Pan_2007\"\n",
    "    fig, ax = plt.subplots(figsize = (8,4))\n",
    "    ax = sns.countplot(data, x = 'Pan_2007', hue = 'Biome_obs')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    save_plot(fig, figurename = 'countplot_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    ## sample biomes\n",
    "    obs_data = \"Biome_obs_ISO3\"\n",
    "    fig, ax = plt.subplots(figsize = (8,4))\n",
    "    ax = sns.countplot(data, x = 'ISO3', hue = 'Biome_obs')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    save_plot(fig, figurename = 'countplot_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    ## scatterplot biome_Cmax and biome_LAI\n",
    "    obs_data = \"Biome_obs_Biome_Cmax\"\n",
    "    fig, ax = plt.subplots(figsize = (4,4))\n",
    "    ax = sns.scatterplot(data, x = \"Biome_Cmax\", y = \"Biome_obs\")\n",
    "    ax.set_yticks(range(1, 20,2))\n",
    "    save_plot(fig, figurename = 'scatterplot_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    '''\n",
    "    obs_data = \"Biome_obs_Biome_LAI\"\n",
    "    fig, ax = plt.subplots(figsize = (4,4))\n",
    "    ax = sns.scatterplot(data, x = \"Biome_LAI\", y = \"Biome_obs\")\n",
    "    ax.set_yticks(range(1, 20,2))\n",
    "    save_plot(fig, figurename = 'scatterplot_' + name_data + '_' + obs_data)\n",
    "    '''\n",
    "    \n",
    "    # NPP\n",
    "    obs_data = \"NPP\"\n",
    "    fig, axs = plt.subplots( 1,2, constrained_layout=True)\n",
    "    sns.histplot(data, x=obs_data,  kde=True, ax=axs[0]) #stat=\"density\", kde=True,, log_scale=True\n",
    "    sns.ecdfplot(data, x=\"NPP\", ax=axs[1])\n",
    "    save_plot(fig, figurename = 'histogramm_' + name_data + '_' + obs_data)\n",
    "    \n",
    "    #\"VegC\"\n",
    "    obs_data = \"VegC\"\n",
    "    fig, axs = plt.subplots(1,2, constrained_layout=True)\n",
    "    sns.histplot(data, x=obs_data,   kde=True, ax=axs[0]) #stat=\"density\", kde=True,binwidth=1,\n",
    "    sns.ecdfplot(data, x=\"VegC\", ax=axs[1])\n",
    "    save_plot(fig, figurename = 'histogramm_' + name_data + '_' + obs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_params = ['pre','tmp|tmin|tmax','tswrf']\n",
    "\n",
    "features_weather = [feature_name for feature_name in list(data_index_2) if \\\n",
    "                   re.search('Fall|Summer|Winter|Spring',feature_name)]\n",
    "\n",
    "liste = ['Lat', 'Lon', 'UN', 'GFED-region', 'Biome_obs', 'Biome_LAI', 'Biome_Cmax']+features_weather\n",
    "\n",
    "print(data_index_2.head())\n",
    "print(data_index_2.drop(liste, axis=1).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot to count the number of data for each biom: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.scatterplot(data_index_2, x=\"Lon\", y=\"Lat\", hue=\"Biome_obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_statistics(data_index_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biome with index 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index_2.loc[data_index_2['Biome_obs'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Classifiaction and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following function generates X_test, Y_test and X_train, Y_train for the binary classification\n",
    "def model_create_XY(region_train, region_test, \\\n",
    "                     drop_columns=[], use_columns=None, \\\n",
    "                        objective='Biome_obs', objective_list=None, continuous_Y=False,\n",
    "                        objective_test=None, drop_LPG_guess=True):\n",
    "      \n",
    "      drop_columns = drop_columns.copy() + [objective] # we would not want our objective to appear in the training data\n",
    "      if not objective_test: objective_test = objective\n",
    "\n",
    "      # restrict to two biomes, restrict to country codes, remove any rows with NaN\n",
    "      if not continuous_Y:\n",
    "            if not objective_list: objective_list=list(data_index_2.loc[region_train][objective].drop_duplicates())\n",
    "            relevant_data_train = data_index_2.loc[data_index_2[objective].isin(objective_list)] # restrict to given biomes\n",
    "            # in case we want to use LPJ_guess output, write LPJ_ before the objective_list\n",
    "            relevant_data_test = data_index_2.loc[data_index_2[objective_test].isin(objective_list)] # restrict to given biomes\n",
    "      else:\n",
    "            relevant_data_train = data_index_2\n",
    "            relevant_data_test = data_index_2\n",
    "\n",
    "                  \n",
    "      relevant_data_train = relevant_data_train.loc[region_train] # restrict to training country\n",
    "      relevant_data_test = relevant_data_test.loc[region_test] # restrict to test country\n",
    "\n",
    "      drop_columns += ['MaxBiomeLAI','Biome_obs','Biome_LAI','Biome_Cmax',\n",
    "                       'Lon','Lat','Pan_2007','ISO3','UN','MaxBiomeCmax']\n",
    "      if drop_LPG_guess: drop_columns += ['CN','pH','cellfraction','NPP','VegC','SoilC','LitterC','SoilR','GFED-region'] # drop these columns\n",
    "      if use_columns:\n",
    "            X_train = relevant_data_train[use_columns]\n",
    "            X_test = relevant_data_test[use_columns]\n",
    "      else:\n",
    "            X_train = relevant_data_train.drop(columns=drop_columns)\n",
    "            X_test = relevant_data_test.drop(columns=drop_columns)\n",
    "\n",
    "      feature_names = list(X_train.columns)\n",
    "\n",
    "      Y_train = relevant_data_train[objective]\n",
    "      Y_test = relevant_data_test[objective_test]\n",
    "\n",
    "      print(f\"length of training data: {Y_train.shape[0]}\")\n",
    "      print(f\"length of testing data: {Y_test.shape[0]}\")\n",
    "      \n",
    "\n",
    "      return X_train, X_test, Y_train, Y_test, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Feature importance (Permutation importance vs. purity importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Notes\n",
    "- The more accurate model is, the more trustworthy computed importances are.\n",
    "- The computed importances describe how important features are for the machine learning model. It is an approximation of how important features are in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_importance(clf, X, y, ax):\n",
    "    result = permutation_importance(clf, X, y,  n_repeats=10, random_state=42, n_jobs=2) # n_repeats=10, random_state=42, n_jobs=2\n",
    "    perm_sorted_idx = result.importances_mean.argsort()\n",
    "    \n",
    "    x_val = X.columns[perm_sorted_idx]\n",
    "    y_val = result.importances[perm_sorted_idx].mean(axis=1).T\n",
    "    \n",
    "    ax.barh(x_val[-5:], y_val[-5:])\n",
    "    ax.tick_params(axis='y', which = 'minor', labelsize=10)\n",
    "    #ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    return ax\n",
    "\n",
    "def plot_permutation_importance_big_graph(clf, X_train, X_test,  Y_train, Y_test, experiment_name):\n",
    "\n",
    "    mdi_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
    "    # tree_importance_sorted_idx = np.argsort(clf.feature_importances_)\n",
    "    # tree_indices = np.arange(0, len(clf.feature_importances_)) + 0.5\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 4))\n",
    "    y = mdi_importances.sort_values()\n",
    "    y[-5:].plot.barh(ax=ax1)\n",
    "    ax1.set_xlabel(\"Gini importance\")\n",
    "    plot_permutation_importance(clf, X_train, Y_train, ax2)\n",
    "    ax2.set_xlabel(\"Decrease in accuracy \")\n",
    "    #fig.suptitle(\n",
    "     #   \"Impurity-based vs. permutation importances on multicollinear features\"\n",
    "    #)\n",
    "    plot_permutation_importance(clf, X_test, Y_test, ax3)\n",
    "    ax3.set_xlabel(\"Decrease in accuracy\")\n",
    "    _ = fig.tight_layout()\n",
    "    save_plot(fig, figurename = 'histogramm_feature_imp'+ experiment_name )\n",
    "    return fig\n",
    "\n",
    "def clustering(clf, X_train, X_test,  Y_train, Y_test, experiment_name, continuous_Y=False):\n",
    "    \n",
    "    \n",
    "    fig, (ax1) = plt.subplots( figsize=(6,7))\n",
    "    corr = spearmanr(X_train).correlation\n",
    "\n",
    "    # Ensure the correlation matrix is symmetric\n",
    "    corr = (corr + corr.T) / 2\n",
    "    np.fill_diagonal(corr, 1)\n",
    "\n",
    "    # We convert the correlation matrix to a distance matrix before performing\n",
    "    # hierarchical clustering using Ward's linkage.\n",
    "    distance_matrix = 1 - np.abs(corr)\n",
    "    dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "    dendro = hierarchy.dendrogram(\n",
    "        dist_linkage, labels=X_train.columns.to_list(), ax=ax1, leaf_rotation=90\n",
    "    )\n",
    "    dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "    \n",
    "    cluster_ids = hierarchy.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "    cluster_id_to_feature_ids = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "    selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "    selected_features_names = X_train.columns[selected_features]\n",
    "    selected_features_names = selected_features_names.tolist()\n",
    "    \n",
    "    X_train_sel = X_train[selected_features_names]\n",
    "    X_test_sel = X_test[selected_features_names]\n",
    "\n",
    "    clf_sel = clf\n",
    "    clf_sel.fit(X_train_sel, Y_train)\n",
    "    if not continuous_Y:\n",
    "        print(\n",
    "            \"Baseline accuracy on test data with features removed:\"\n",
    "            f\" {accuracy_score(Y_test, clf.predict(X_test_sel)):.4}\"\n",
    "            \"Baseline balanced accuracy on test data with features removed:\"\n",
    "            f\" {balanced_accuracy_score(Y_test, clf.predict(X_test_sel)):.4}\"\n",
    "        )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    plot_permutation_importance(clf_sel, X_test_sel, Y_test, ax)\n",
    "    #ax.set_title(\"Permutation Importances on selected subset of features\\n(test set)\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    save_plot(fig, figurename = 'histogramm_feature_imp_clustered'+ experiment_name )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following generates, trains and evaluates the model\n",
    "def model_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n",
    "                         hyperparameter_tuning=False, feature_plots=False, experiment_name=None):\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    \n",
    "    if hyperparameter_tuning==4: # for testing parameters manually\n",
    "        clf = RandomForestClassifier(random_state=0, max_depth=10, n_estimators=100, min_samples_leaf=1)\n",
    "    elif hyperparameter_tuning:\n",
    "        X_hyper, Y_hyper = X_train, Y_train\n",
    "        # X_hyper,_,Y_hyper,_ = skm.train_test_split(X_train, Y_train, train_size=300,random_state=0)\n",
    "        kfold3 = skm.KFold(3,\n",
    "                        random_state=1,\n",
    "                        shuffle=True) # let's try fewer fold to save running time\n",
    "\n",
    "        fineness = 10 # determines how many parameters should be tested\n",
    "        params = {\n",
    "                'max_depth': np.linspace(5, 15, 1).astype('int'), # (5,15)\n",
    "                'n_estimators': np.linspace(50, 150, fineness).astype('int'), #50, 150 (10,40) CV number of trees, keep this low for part 4\n",
    "                'min_samples_leaf': np.linspace(1, 5, fineness).astype('int'), # minimum leaf number\n",
    "                }\n",
    "        if False:\n",
    "            rfc_gscv = GridSearchCV(clf, param_grid = params, scoring = \"accuracy\",\n",
    "                                        cv = kfold3 )\n",
    "        else:\n",
    "            # Alternatively use HalvingGridSearchCV which is equally abismal in its performance\n",
    "            rfc_gscv = HalvingGridSearchCV(clf, param_grid = params, scoring = \"accuracy\",\n",
    "                                        cv = kfold3, min_resources=20, max_resources=30)\n",
    "        \n",
    "        # Fit the model\n",
    "        model_rfc = rfc_gscv.fit(X_hyper, Y_hyper)\n",
    "\n",
    "        # Model best estimator\n",
    "        max_depths=model_rfc.best_estimator_.get_params()[\"max_depth\"]\n",
    "        max_trees= model_rfc.best_estimator_.get_params()[\"n_estimators\"]\n",
    "        min_samples_leaf= model_rfc.best_estimator_.get_params()[\"min_samples_leaf\"]\n",
    "        max_cvs= rfc_gscv.best_score_\n",
    "        print(\"Max Depth: \", max_depths)\n",
    "        print(\"Max Trees: \",max_trees)\n",
    "        print(\"Min Leafs: \",min_samples_leaf)\n",
    "        print(\"Max CV: \",max_cvs)\n",
    "\n",
    "        clf = RandomForestClassifier(random_state=0, max_depth=max_depths, n_estimators=max_trees, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Some performance \n",
    "    score_rfc_train = accuracy_score(Y_train, clf.predict(X_train))\n",
    "    print('Accuracy of RandomForestClassifier on train data: {:.4f}'.format(score_rfc_train))\n",
    "    balance_score_rfc_train = balanced_accuracy_score(Y_train, clf.predict(X_train))\n",
    "    print('Balanced accuracy of RandomForestClassifier on train data: {:.4f}'.format(balance_score_rfc_train))\n",
    "    \n",
    "    kfold = skm.KFold(3, random_state=1, shuffle=True)\n",
    "    # This becomes computationally quite expensive for large training sets\n",
    "    scores_rfc_val = cross_val_score(clf, X_train, Y_train, cv=kfold)\n",
    "    print(\"Accuracy RandomForestClassifier on cross validation: %0.4f ( %0.2f)\" % (scores_rfc_val.mean(), scores_rfc_val.std()))\n",
    "\n",
    "    score_rfc_test = accuracy_score(Y_test, clf.predict(X_test))\n",
    "    print('Accuracy of RandomForestClassifier on test data: {:.4f}'.format(score_rfc_test))\n",
    "    balance_score_rfc_test = balanced_accuracy_score(Y_test, clf.predict(X_test))\n",
    "    print('Balanced accuracy of RandomForestClassifier on train data: {:.4f}'.format(balance_score_rfc_test))\n",
    "    \n",
    "    # confusion table\n",
    "    display(Markdown('---\\n The confusion table'))\n",
    "    conf_table = confusion_table(clf.predict(X_test),\n",
    "                            Y_test)\n",
    "    display(conf_table)\n",
    "    if experiment_name:\n",
    "        df_to_latex(conf_table, f'{experiment_name}_confTable', caption='Confusion matrix.')\n",
    "    \n",
    "    classreport = classification_report(Y_test, clf.predict(X_test), zero_division = np.nan, output_dict=True)\n",
    "    classreport = pd.DataFrame(classreport).transpose()\n",
    "    display(classreport)\n",
    "    if experiment_name:\n",
    "        df_to_latex(classreport, f'{experiment_name}_classreport')\n",
    "    \n",
    "    # display importance table\n",
    "    display(Markdown('---\\n The feature importance'))\n",
    "    feature_impo = clf.feature_importances_\n",
    "    feature_imp = pd.DataFrame(\n",
    "    {'importance':clf.feature_importances_},\n",
    "    index=feature_names)\n",
    "    feature_imp = feature_imp.sort_values(by='importance', ascending=False)\n",
    "    display(feature_imp)\n",
    "    if experiment_name:\n",
    "        df_to_latex(feature_imp, f'{experiment_name}_featureImportance')\n",
    "    \n",
    "    if feature_plots:\n",
    "        # Plot Impurity-based vs. Permutation importance\n",
    "        plot_permutation_importance_big_graph(clf, X_train, X_test,  Y_train, Y_test, experiment_name)\n",
    "        \n",
    "        clustering(clf, X_train, X_test,  Y_train, Y_test,  experiment_name)\n",
    "        \n",
    "    display(Markdown('---'))\n",
    "\n",
    "    # return in the format\n",
    "    # ['accuracy, train', 'balanced accuracy, train', 'cross val accuracy, train',\n",
    "    #  'accuracy, test', 'balanced accuracy, test']\n",
    "\n",
    "    return [score_rfc_train ,balance_score_rfc_train, scores_rfc_val, \n",
    "            score_rfc_test, balance_score_rfc_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n",
    "                         hyperparameter_tuning=False, feature_plots=False, experiment_name=None):\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(X_train, Y_train)\n",
    "\n",
    "    score_reg_train = reg.score(X_train, Y_train)\n",
    "    #Return the coefficient of determination of the prediction (R^2 score)\n",
    "    \n",
    "    print('R^2 Score of RandomForestRegressor on train data: {:.4f}'.format(score_reg_train))\n",
    "    # The following takes way to long for large training sets\n",
    "    # kfold = skm.KFold(3, random_state=1, shuffle=True)\n",
    "    # scores_reg_val = cross_val_score(reg, X_train, Y_train, cv=kfold)\n",
    "    # print(\"Accuracy RandomForestRegressor on cross validation: %0.4f ( %0.2f)\" % (scores_reg_val.mean(), scores_reg_val.std()))\n",
    "    score_reg_test = reg.score(X_test, Y_test)\n",
    "    print('R^2 Score of RandomForestRegressor on test data: {:.4f}'.format(score_reg_test))\n",
    "\n",
    "    # MSE\n",
    "    Y_hat = reg.predict(X_test)\n",
    "    mse = np.mean((Y_test - Y_hat)**2)\n",
    "    print(f'MSE for test data {mse}')\n",
    "\n",
    "    mse2 = mean_squared_error(Y_test,Y_hat)\n",
    "    print(f'MSE (with sktfct) for test  data {mse2}')\n",
    "\n",
    "    # SQRT(MSE)\n",
    "    sqrtmse = np.sqrt(mse)\n",
    "    print(f'sqrt(MSE) for test data {sqrtmse}')\n",
    "    \n",
    "    # maximum Error\n",
    "    max_err = max_error(Y_test, Y_hat)\n",
    "    print(f'max error for test data {max_err}')\n",
    "\n",
    "    # mean absolute error\n",
    "    mean_abs_err = mean_absolute_error(Y_test, Y_hat)\n",
    "    print(f'mean abs error for test data {mean_abs_err}')\n",
    "\n",
    "    #PredictionErrorDisplay(Y_test, Y_hat)\n",
    "\n",
    "    # fig, ax = subplots()\n",
    "    plt_data = pd.DataFrame(np.concatenate([[Y_hat],[Y_test]])).transpose()\n",
    "    plt_data = plt_data.rename(columns={0:'Y_hat',1:'Y_test'})\n",
    "    # ax.scatter(Y_hat, Y_test)\n",
    "    ax = sns.relplot(data=plt_data,x='Y_hat',y='Y_test').ax\n",
    "    ax.set_xlabel('predicted sample $\\hat{Y}$')\n",
    "    ax.set_ylabel('exact sample $Y_{test}$')\n",
    "    maxval = max([np.max(Y_test),np.max(Y_hat)])\n",
    "    ax.plot([0,maxval],[0,maxval],color='red',markersize=1)\n",
    "    if experiment_name: save_plot(plt.gcf(), f'{experiment_name}_regressionPlot')\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.hist(Y_test-Y_hat, bins=50, density=True)\n",
    "    ax = sns.displot(Y_test-Y_hat, kde=True).ax\n",
    "    ax.set_xlabel('residue $Y_{test}-\\hat{Y}$')\n",
    "    ax.set_ylabel('Share of samples')\n",
    "    if experiment_name: save_plot(plt.gcf(), f'{experiment_name}_residualDistr')\n",
    "    \n",
    "    # display importance table\n",
    "    display(Markdown('---\\n The feature importance'))\n",
    "    feature_impo = reg.feature_importances_\n",
    "    feature_imp = pd.DataFrame(\n",
    "    {'importance':reg.feature_importances_},\n",
    "    index=feature_names)\n",
    "    feature_imp = feature_imp.sort_values(by='importance', ascending=False)\n",
    "    display(feature_imp)\n",
    "    if experiment_name:\n",
    "        df_to_latex(feature_imp, f'{experiment_name}_featureImportance')\n",
    "\n",
    "    \n",
    "    if feature_plots:\n",
    "        # Plot Impurity-based vs. Permutation importance\n",
    "        plot_permutation_importance_big_graph(reg, X_train, X_test,  Y_train, Y_test, experiment_name)\n",
    "        \n",
    "        clustering(reg, X_train, X_test,  Y_train, Y_test,  experiment_name, True)\n",
    "    display(Markdown('---'))\n",
    "    # ['R^2 score, train', 'score, test', 'MSE, test', 'MSE sktfct, test', 'sqrt(MSE)', 'max err', 'mean abs err']\n",
    "    return [score_reg_train, score_reg_test, mse, mse2, sqrtmse, max_err, mean_abs_err]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about R2 score - which is the accuracz in the regression case: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score\n",
    "\n",
    "In cases where negative values arise, the mean of the data provides a better fit to the outcomes than do the fitted function values, according to this particular criterion. (Wikipedia: https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model \n",
    "continuous_Y = True gives regression, else classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run the training data, test data and the model\n",
    "def model_run(region_train, region_test, objective='Biome_obs', objective_list=None, \\\n",
    "                drop_columns=[], use_columns=None, \\\n",
    "                hyperparameter_tuning=False, continuous_Y=False, objective_test=None, \\\n",
    "                    feature_plots=False, experiment_name=None, drop_LPG_guess=True):\n",
    "    X_train, X_test, Y_train, Y_test, feature_names = model_create_XY(region_train, \\\n",
    "                        region_test, drop_columns, use_columns, objective, \\\n",
    "                              objective_list, continuous_Y, objective_test, drop_LPG_guess)\n",
    "    if continuous_Y:\n",
    "        return regression_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n",
    "                         hyperparameter_tuning, feature_plots, experiment_name)\n",
    "    else:\n",
    "        return model_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n",
    "                         hyperparameter_tuning, feature_plots, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that `NaN` appeard somewhere in `data_index_2`. The following is to find out where it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_index_2.loc[:,data_index_2.isna().any()]))\n",
    "data_index_2[data_index_2.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose countries. Random.org gave us the biomes\n",
    "- 17: desert\n",
    "- 16: Arid shrub/steppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biome_list_3 = [17,16] # our chosen biomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_data = data_index_2.loc[data_index_2['Biome_obs'].isin(biome_list_3)]\n",
    "relevant_data = relevant_data[~(relevant_data.isna().any(axis=1))] # delete rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_statistics(relevant_data, name_data = 'Section3Biome17_and_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we choose Egypt to train and China as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_train_3 = data_index_2['ISO3'] == 'EGY' # egypt is the chosen one\n",
    "region_test_3 = data_index_2['ISO3'] == 'LBY' # libya is the chosen one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "data1 = relevant_data.loc[region_train_3] \n",
    "data2 = relevant_data.loc[region_test_3]\n",
    "\n",
    "data = pd.concat([data1,data2])\n",
    "#plot_statistics(data, name_data = 'Section3EGY-CHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_climate_diagramm(region):\n",
    "    fig, ax1=plt.subplots()\n",
    "\n",
    "    tmp = Tmpdaymean.loc[region].transpose()[2:]\n",
    "    tmp.reset_index(inplace=True, drop=True)\n",
    "    tmp = tmp.stack(level=0).droplevel(1)\n",
    "    tmp_df = pd.DataFrame({'day':tmp.index, 'tmp':tmp.values})\n",
    "    tmp_df['tmp'] -= 273.15\n",
    "    sns.lineplot(ax=ax1, data=tmp_df, x=\"day\", y=\"tmp\", color='red')\n",
    "\n",
    "    ax2 =ax1.twinx()\n",
    "    tmp = Predaymean.loc[region].transpose()[2:]\n",
    "    tmp.reset_index(inplace=True, drop=True)\n",
    "    tmp = tmp.stack(level=0).droplevel(1)\n",
    "    tmp_df = pd.DataFrame({'day':tmp.index, 'prec':tmp.values})\n",
    "    sns.lineplot(ax=ax2, data=tmp_df, x=\"day\", y=\"prec\", color='blue')\n",
    "\n",
    "    ax1.set_ylabel('Temperature (C)')\n",
    "    ax2.set_ylabel('Precipitation (mm) / day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot climate diagramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_climate_diagramm(region_test_3)\n",
    "save_plot(plt.gcf(), 'climate_egypt')\n",
    "plot_climate_diagramm(region_test_3 & (data_index_2['Biome_obs']==17))\n",
    "save_plot(plt.gcf(), 'climate_egypt_desert')\n",
    "plot_climate_diagramm(region_test_3 & (data_index_2['Biome_obs']==16))\n",
    "save_plot(plt.gcf(), 'climate_egypt_aridShrub')\n",
    "plot_climate_diagramm(region_train_3)\n",
    "save_plot(plt.gcf(), 'climate_libya')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the action starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_3, region_test_3, objective_list=biome_list_3, feature_plots=True, experiment_name='s3_basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now run a series of tests, collecting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_median = [feature_name for feature_name in list(data_index_2) if feature_name[-6:]=='Median']\n",
    "features_weather = [feature_name for feature_name in list(data_index_2) if \\\n",
    "                   re.search('Fall|Summer|Winter|Spring',feature_name)]\n",
    "seasons = ['Fall','Summer','Winter','Spring']\n",
    "features_seasons = [[feature_name for feature_name in list(data_index_2) if \\\n",
    "                   re.search(season,feature_name)] for season in seasons]\n",
    "weather_params = ['pre','tmp|tmin|tmax','tswrf']\n",
    "features_weather_params = [[feature_name for feature_name in list(data_index_2) if \\\n",
    "                   re.search(weather_param,feature_name)] for weather_param in weather_params]\n",
    "\n",
    "features_nonweather = ['clay','silt','sand','orgC']\n",
    "\n",
    "features_names = ['median']+['non-climate']+['climate']+[season for season in seasons]+[weather_param for weather_param in weather_params]\n",
    "drop_features = [features_median]+[features_nonweather]+[features_weather]+[features_season for features_season in features_seasons]\\\n",
    "                +[features_weather_param for features_weather_param in features_weather_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run a series of tests, collecting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "performance = model_run(region_train_3, region_test_3, objective_list=biome_list_3, experiment_name='s3_basic')\n",
    "simulation_comparisons_3 = pd.DataFrame([['base']+performance], columns=['experiment name','accuracy, train', 'balanced accuracy, train', 'cross val accuracy, train',\n",
    "            'accuracy, test', 'balanced accuracy, test'])\n",
    "\n",
    "for i,feature_name in enumerate(features_names):\n",
    "    display(Markdown('---'))\n",
    "    print(f'Dropping season {feature_name}')\n",
    "    print(f'We dropped the features: {drop_features[i]}')\n",
    "    performance = model_run(region_train_3, region_test_3, objective_list=biome_list_3, \\\n",
    "               drop_columns=drop_features[i], experiment_name=f's3_drop_{feature_name.replace(\"|\",\"_\")}')\n",
    "    \n",
    "    simulation_comparisons_3 = pd.concat([simulation_comparisons_3, pd.DataFrame([[f'drop {feature_name}']+performance], columns=list(simulation_comparisons_3))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_comparisons_3.to_pickle('../data/simulation_comparisons_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparisons_data(simulation_comparisons, experiment_name=None):\n",
    "    simulation_comparisons['error rate, test']= 1-simulation_comparisons['accuracy, test']\n",
    "    ax = sns.barplot(simulation_comparisons[['experiment name','error rate, test']], x='experiment name', y='error rate, test')\n",
    "    ax.set_ylabel('Error rate')\n",
    "    ax.set_xlabel('')\n",
    "    plt.axhline(y=simulation_comparisons['error rate, test'][0], color='blue',linestyle='--')\n",
    "    plt.xticks(rotation=90);\n",
    "    if experiment_name: save_plot(plt.gcf(), f'{experiment_name}_simulationComparisons_errorRate')\n",
    "\n",
    "    plt.subplots()\n",
    "    simulation_comparisons['balanced error rate, test'] = 1-simulation_comparisons['balanced accuracy, test']\n",
    "    ax = sns.barplot(simulation_comparisons[['experiment name','balanced error rate, test']], x='experiment name', y='balanced error rate, test')\n",
    "    ax.set_ylabel('Balanced error rate')\n",
    "    ax.set_xlabel('')\n",
    "    plt.axhline(y=simulation_comparisons['balanced error rate, test'][0], color='blue',linestyle='--')\n",
    "    plt.xticks(rotation=90);\n",
    "    if experiment_name: save_plot(plt.gcf(), f'{experiment_name}_simulationComparisons_balancedErrorRate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_comparisons_3 = simulation_comparisons_3.reset_index(drop=True)\n",
    "plot_comparisons_data(simulation_comparisons_3, 's3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the significant negative impact on the learning outcome by choosing regions at very different latitudes we chose as regions\n",
    "- for training: Russia\n",
    "- for testing: Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_train_4 = data_index_2['Pan_2007'] == 'Russia'\n",
    "region_test_4 = data_index_2['Pan_2007'] == 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "data1 = data_index_2.loc[region_train_4] \n",
    "data2 = data_index_2.loc[region_test_4]\n",
    "\n",
    "data = pd.concat([data1,data2])\n",
    "plot_statistics(data, name_data = 'Section4Canada_Russia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, experiment_name='s4_basic', feature_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is relatively bad performance. Fiddling with the hyperparameters changes a lot though the\n",
    "hyperparameter optimisation is far from optimal. Let's see how good it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data: 11696\n",
      "length of testing data: 6497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb Cell 87\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_run(region_train_4, region_test_4, hyperparameter_tuning\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, experiment_name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mTuning\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb Cell 87\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m regression_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                      hyperparameter_tuning, feature_plots, experiment_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model_train_evaluate(X_train, X_test, Y_train, Y_test, feature_names, \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                      hyperparameter_tuning, feature_plots, experiment_name)\n",
      "\u001b[1;32m/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb Cell 87\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     rfc_gscv \u001b[39m=\u001b[39m HalvingGridSearchCV(clf, param_grid \u001b[39m=\u001b[39m params, scoring \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                                 cv \u001b[39m=\u001b[39m kfold3, min_resources\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, max_resources\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model_rfc \u001b[39m=\u001b[39m rfc_gscv\u001b[39m.\u001b[39;49mfit(X_hyper, Y_hyper)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Model best estimator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/64BB-4184/Filing/Education/University/Lund/Courses/ModellingComputationalScience/computational-science-HT23/Project3/Project3RandomForestML/code/main.ipynb#Y152sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m max_depths\u001b[39m=\u001b[39mmodel_rfc\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mget_params()[\u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:257\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    250\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    251\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m    252\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 257\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    259\u001b[0m \u001b[39m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_results_[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_index_]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:361\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    354\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    356\u001b[0m more_results \u001b[39m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: [itr] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    358\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_resources\u001b[39m\u001b[39m\"\u001b[39m: [n_resources] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    359\u001b[0m }\n\u001b[0;32m--> 361\u001b[0m results \u001b[39m=\u001b[39m evaluate_candidates(\n\u001b[1;32m    362\u001b[0m     candidate_params, cv, more_results\u001b[39m=\u001b[39;49mmore_results\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    365\u001b[0m n_candidates_to_keep \u001b[39m=\u001b[39m ceil(n_candidates \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor)\n\u001b[1;32m    366\u001b[0m candidate_params \u001b[39m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:754\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    751\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    753\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m--> 754\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[1;32m    755\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:813\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    811\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    812\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 813\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[1;32m    814\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    816\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     _kwargs[\u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sample_weight\n\u001b[0;32m--> 266\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_score(partial(_cached_call, \u001b[39mNone\u001b[39;49;00m), estimator, X, y_true, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_overlap(\n\u001b[1;32m    346\u001b[0m     message\u001b[39m=\u001b[39m(\n\u001b[1;32m    347\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[1;32m    354\u001b[0m scoring_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    355\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m response_method \u001b[39min\u001b[39;00m cache:\n\u001b[1;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 86\u001b[0m result, _ \u001b[39m=\u001b[39m _get_response_values(\n\u001b[1;32m     87\u001b[0m     estimator, \u001b[39m*\u001b[39;49margs, response_method\u001b[39m=\u001b[39;49mresponse_method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     cache[response_method] \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/_response.py:85\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m target_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     83\u001b[0m     pos_label \u001b[39m=\u001b[39m pos_label \u001b[39mif\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m classes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 85\u001b[0m y_pred \u001b[39m=\u001b[39m prediction_method(X)\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m prediction_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m target_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    871\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[1;32m    872\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    873\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m    874\u001b[0m ]\n\u001b[1;32m    875\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 876\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m    877\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    878\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[1;32m    882\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:647\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[1;32m    641\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[1;32m    649\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/tree/_classes.py:992\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict class probabilities of the input samples X.\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \n\u001b[1;32m    970\u001b[0m \u001b[39mThe predicted class probability is the fraction of samples of the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[39m    classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    991\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[1;32m    993\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/tree/_classes.py:473\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     \u001b[39m# The number of features is checked regardless of `check_input`\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    474\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/base.py:391\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set the `n_features_in_` attribute, or check against it.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[1;32m    376\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     n_features \u001b[39m=\u001b[39m _num_features(X)\n\u001b[1;32m    392\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reset \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/statLearnEnvironment/lib/python3.10/site-packages/sklearn/utils/validation.py:297\u001b[0m, in \u001b[0;36m_num_features\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_num_features\u001b[39m(X):\n\u001b[1;32m    280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the number of features in an array-like X.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m \u001b[39m    This helper function tries hard to avoid to materialize an array version\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m        Number of features\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     type_ \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39;49m(X)\n\u001b[1;32m    298\u001b[0m     \u001b[39mif\u001b[39;00m type_\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbuiltins\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    299\u001b[0m         type_name \u001b[39m=\u001b[39m type_\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_run(region_train_4, region_test_4, hyperparameter_tuning=True, experiment_name = 'Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not too good in this case. But when we were previously comparing Africa with China fiddling with the parameters actually did improve things. In the following we will thus disable the hyperparameter tuning. Let's try dropping various features and see how that impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "performance = model_run(region_train_4, region_test_4, experiment_name='s4_basic')\n",
    "simulation_comparisons_4 = pd.DataFrame([['base']+performance], columns=['experiment name','accuracy, train', 'balanced accuracy, train', 'cross val accuracy, train',\n",
    "            'accuracy, test', 'balanced accuracy, test'])\n",
    "\n",
    "for i,feature_name in enumerate(features_names):\n",
    "    display(Markdown('---'))\n",
    "    print(f'Dropping season {feature_name}')\n",
    "    print(f'We dropped the features: {drop_features[i]}')\n",
    "    performance = model_run(region_train_4, region_test_4, \\\n",
    "               drop_columns=drop_features[i], experiment_name=f's4_drop_{feature_name.replace(\"|\",\"_\")}')\n",
    "    \n",
    "    simulation_comparisons_4 = pd.concat([simulation_comparisons_4, pd.DataFrame([[f'drop {feature_name}']+performance], columns=list(simulation_comparisons_4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_comparisons_4 = simulation_comparisons_4.reset_index(drop=True)\n",
    "simulation_comparisons_4.to_pickle('../data/simulation_comparisons_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparisons_data(simulation_comparisons_4, 's4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how things are with biome_Cmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, feature_plots = True, objective='Biome_Cmax', experiment_name = 'Basic_with_Biome_Cmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, hyperparameter_tuning=True, feature_plots = False, objective='Biome_Cmax', experiment_name = 's4Basic_with_Biome_Cmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "performance = model_run(region_train_4, region_test_4, objective='Biome_Cmax', experiment_name='s4_basic')\n",
    "simulation_comparisons_4 = pd.DataFrame([['base']+performance], columns=['experiment name','accuracy, train', 'balanced accuracy, train', 'cross val accuracy, train',\n",
    "            'accuracy, test', 'balanced accuracy, test'])\n",
    "\n",
    "for i,feature_name in enumerate(features_names):\n",
    "    display(Markdown('---'))\n",
    "    print(f'Dropping season {feature_name}')\n",
    "    print(f'We dropped the features: {drop_features[i]}')\n",
    "    performance = model_run(region_train_4, region_test_4, objective='Biome_Cmax',\\\n",
    "               drop_columns=drop_features[i], experiment_name=f's4_drop_{feature_name.replace(\"|\",\"_\")}')\n",
    "    \n",
    "    simulation_comparisons_4 = pd.concat([simulation_comparisons_4, pd.DataFrame([[f'drop {feature_name}']+performance], columns=list(simulation_comparisons_4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_comparisons_4 = simulation_comparisons_4.reset_index(drop=True)\n",
    "simulation_comparisons_4.to_pickle('../data/simulation_comparisons_4_Cmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAIcCAYAAAAKQ49bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgXElEQVR4nO3deVhUZf8/8PcAsikCIqIisoQiuBJUCrmghkupUT1RlKRixWMugGKambtWKpKZW+aW5YO5tZlKgihg+Q1wS01SFFKUwBQVBYHz+4Mfk8MMMKPAWXi/rmuuy7nnzPAGYc5n7nMvKkEQBBAREREphJHYAYiIiIjqEosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBTFROwADa28vBxXrlyBlZUVVCqV2HGIiIhID4Ig4NatW2jbti2MjGrum2l0xc2VK1fg5OQkdgwiIiJ6CDk5OWjXrl2NxzS64sbKygpAxQ+nefPmIqchIiIifRQWFsLJyUl9Hq9JoytuKi9FNW/enMUNERGRzOgzpIQDiomIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBOxAxBJnU/0ZrEjaEhbHCp2BCIiSWPPDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKVygmIiKqB1zdXDzsuSEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpiujFzcqVK+Hq6gpzc3P4+Pjg8OHDNR5fXFyMGTNmwNnZGWZmZnjsscewfv36BkpLREREUifqruBxcXGIiIjAypUr4e/vjzVr1mDIkCE4ffo02rdvr/M5L7/8Mq5du4YvvvgC7u7uyMvLQ2lpaQMnJyIiIqkStbiJiYlBWFgYxo4dCwCIjY3Fvn37sGrVKixatEjr+L179yIpKQkXLlxAixYtAAAuLi4NGZmIiIgkTrTLUiUlJUhLS0NgYKBGe2BgIFJTU3U+57vvvoOvry8+/vhjODo6omPHjpgyZQru3r1b7dcpLi5GYWGhxo2IiIiUS7Sem/z8fJSVlcHBwUGj3cHBAVevXtX5nAsXLiA5ORnm5ubYtWsX8vPzMW7cOFy/fr3acTeLFi3CnDlz6jw/ERERSZPoA4pVKpXGfUEQtNoqlZeXQ6VS4auvvsKTTz6JoUOHIiYmBhs3bqy292b69Om4efOm+paTk1Pn3wMRERFJh2g9Ny1btoSxsbFWL01eXp5Wb06lNm3awNHREdbW1uo2T09PCIKAv/76Cx06dNB6jpmZGczMzOo2PBEREUmWaD03pqam8PHxQXx8vEZ7fHw8/Pz8dD7H398fV65cwe3bt9Vt586dg5GREdq1a1eveYmIiEgeRL0sFRUVhXXr1mH9+vU4c+YMIiMjkZ2djfDwcAAVl5RCQ0PVx4eEhMDOzg6jR4/G6dOncejQIURHR2PMmDGwsLAQ69sgIiIiCRF1KnhwcDAKCgowd+5c5ObmokuXLtizZw+cnZ0BALm5ucjOzlYf36xZM8THx2PChAnw9fWFnZ0dXn75ZcyfP1+sb4GIiIgkRtTiBgDGjRuHcePG6Xxs48aNWm2dOnXSupRFREREVEn02VJEREREdYnFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFNGLm5UrV8LV1RXm5ubw8fHB4cOHqz324MGDUKlUWrezZ882YGIiIiKSMlGLm7i4OERERGDGjBnIyMhA7969MWTIEGRnZ9f4vD/++AO5ubnqW4cOHRooMREREUmdqMVNTEwMwsLCMHbsWHh6eiI2NhZOTk5YtWpVjc9r1aoVWrdurb4ZGxs3UGIiIiKSOtGKm5KSEqSlpSEwMFCjPTAwEKmpqTU+19vbG23atMGAAQOQmJhY47HFxcUoLCzUuBEREZFyiVbc5Ofno6ysDA4ODhrtDg4OuHr1qs7ntGnTBmvXrsWOHTuwc+dOeHh4YMCAATh06FC1X2fRokWwtrZW35ycnOr0+yAiIiJpMRE7gEql0rgvCIJWWyUPDw94eHio7/fq1Qs5OTlYsmQJ+vTpo/M506dPR1RUlPp+YWEhCxwiIiIFE63npmXLljA2NtbqpcnLy9PqzalJz549kZmZWe3jZmZmaN68ucaNiIiIlEu04sbU1BQ+Pj6Ij4/XaI+Pj4efn5/er5ORkYE2bdrUdTwiIiKSKVEvS0VFRWHkyJHw9fVFr169sHbtWmRnZyM8PBxAxSWly5cvY/PmzQCA2NhYuLi4oHPnzigpKcGWLVuwY8cO7NixQ8xvg4iIiCRE1OImODgYBQUFmDt3LnJzc9GlSxfs2bMHzs7OAIDc3FyNNW9KSkowZcoUXL58GRYWFujcuTN+/PFHDB06VKxvgYgaMZ/ozWJH0JK2OFTsCESiE31A8bhx4zBu3Didj23cuFHj/tSpUzF16tQGSEVERERyJXpxQ0QESK8XhD0gRPIl+t5SRERERHWJxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaJwKjgREREBUM6SDOy5ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESnKQxU358+fx/vvv49XX30VeXl5AIC9e/fi999/r9NwRERERIYyuLhJSkpC165d8euvv2Lnzp24ffs2AODEiROYNWtWnQckIiIiMoTBxc20adMwf/58xMfHw9TUVN0eEBCAI0eO1Gk4IiIiIkMZXNycPHkSQUFBWu329vYoKCiok1BERERED8vg4sbGxga5ubla7RkZGXB0dKyTUEREREQPy+DiJiQkBO+++y6uXr0KlUqF8vJypKSkYMqUKQgNfbiVBImIiIjqisHbLyxYsACjRo2Co6MjBEGAl5cXysrKEBISgvfff78+MlI15LhMthwzExGRvBhc3DRp0gRfffUV5s2bh/T0dJSXl8Pb2xsdOnSoj3xEREREBjG4uJk7dy6mTJkCNzc3uLm5qdvv3r2LxYsX44MPPqjTgERkOPaQEVFjZvCYmzlz5qjXtnlQUVER5syZUyehiIiIiB6WwcWNIAhQqVRa7cePH0eLFi3qJBQRERHRw9L7spStrS1UKhVUKhU6duyoUeCUlZXh9u3bCA8Pr5eQRERUd3jZkpRO7+ImNjYWgiBgzJgxmDNnDqytrdWPmZqawsXFBb169aqXkERERET60ru4eeONNwAArq6u8PPzQ5MmTeotFBEREdHDMni2VN++fdX/vnv3Lu7fv6/xePPmzR89FREREdFDMri4KSoqwtSpU7Ft2zade0mVlZXVSbD6ducOYGys3W5sDJibax5XHSMjwMLi4Y4tKgIEQfexKhVgaVn7sWUlJlCpBBg1+fdnXn7fGIKgPeC7krFp6cMdW2oEobz68ecPHnvvHlDdr0FZiQmMmpSicshWba/70MeWGUEo0+/YkhKgSo2uQShXQWUk6Pe6JmXqY4UyFcrLdPySPeKxpaVAcXH1eR/YzxZCuQrlpTW8rnEZVMaCXseqjMthZFxu+LFCzX8bTZr8m1kQgPL71b8tqYzKYWRSXq/HAhW/p9VlrvoeUVZSw+tW+fs05Nia/j5rOrZq7qrvJ3fv1pyjId4jqh5bNbOlJdR/n8XFFb/z1THkWAuLivdioPa/e0OONTf/93zy4LG6fs4N8R5R3d9n5c/Z1LTi7w7Qfj+pmrmh3iOq+/u8c0fzPUJfBhc30dHRSExMxMqVKxEaGorPPvsMly9fxpo1a/Dhhx8a+nKiadtWd/vQocCPP/57v1WriuJCl759gYMH/73v4gLk5+s+1tcX+L//+/e+lxdw6ZLuY728gN9///f+E08Ap0/rOjIEps1vo8tbO9Ut5/43CEXXWup8XROLe+j2zjb1/T93DMDtv1rrPNbI5D56RGxV37/wbT8UZrXTHRjA41P+HaA4ciSwfXt1R4ag+8Sv1W902fE9cf1392pft+u4ODSxrPjL++ugL/KPdar22M5v7oCZdcVf75XD3sj7rXO1x3qO+hYWLW8CABYuBGpaxcDjtRZo2qaikP87zROXD/lUe2yHl/fBqv01AED+iY7IOfBUtcc+FnQA1o9dBgBcP+OGS3v9qz3WdVgSbD0qfmF27QJefrn6vBs2/Pvvwqy2OL9rQLXHOg34FfbefwAAbv/VCpnbBlV7rGOfNDg8WfGLWXStBf746tlqj23d6zja+h8HANwrsEazZtXnnTIFWLy44t8lhU3x++cvVntsyx5n0X7gUQBA6V0znFwZXO2xLTr/CZchqQAq3jiPLw+p9libjhfhNvyQ+v7x5SFotlz3sVXfI06u/A/KS3Vfpm/W7io6vrJfff/3z19A6V1zncdaOuSj08g96vunN4xASaHuH5y53Q14jf5Off/slmdxr8Cm4mtWye3sDFy8+O/9Pn2A47/p/lk01HvExT1P48Y5F/X9qplv3waaNq3499tvA5s2VfuyyMsD7O0r/h0VBaxcWf2xWVkV79MAMGMGsGRJ9ceeOgV0/v9vIbW9Rxw9WvE+DQCffAJMnVr5iPbPuSHeI25ktkfW9321jqn8OW/YAIwaVfHvffuA55578CjNzA31HnFm4widxzVbrvkeoS+Di5vvv/8emzdvRr9+/TBmzBj07t0b7u7ucHZ2xldffYXXXnvN0JeUlOQzf8EnOkF9/17JqwB0v3Glnb8Kn+h/37hu3HkZgO43rtM5+fCJ/veNK/efFwDofuO6cO0GABvDghMRNUIDZv/7ASg79UkA1X8Aem7hvx+A/jroA6D6D0D/WfLvB6ArKd0BdK+ryNQAVIJQ3cUR3Zo1a4bff/8dzs7OaNeuHXbu3Iknn3wSWVlZ6Nq1q84F/qSksLAQ1tbWuHLlpsb4IP/3vgagu3u6OvXZ5ZwR+2+RWN1lKf/3vpbUZanK6Zw1XZbyf+9rSV2WSlscWmuXc+8PvpTUZalfF4XWelmq53sVn5Klclnq8Jzqp/pWdjn7RG+W1GWplIW6ezcevCzlE71ZcpelqubWdVmq17Svq80hxmWpqpl1XWqqfI+uqiEuXes69sHM1V2W0pVZzMtSlZlruixVNbPYl6VSFoao3yMqz983b96sdXyvwT03bm5uuHjxIpydneHl5YVt27bhySefxPfffw8bGxtDX040TZv+2+0JaP7hPai69kc99sE3pto8+MZU29cz5HUNOtakHEB5rccBmuMRqqqa2ZDXNehY43LAWL9jTU1rvp5b+YZh6OuqjAUYG+v3O2HIsSYmFTe9XtdI0Pv3st6OVWn+rdV2rCGvWx/HAhXH6ptZCu8RDx5bW24LC/1z1Nd7RNVja8psZlZx0ydzfb1H6Dq2uswPvp/Ulrm+3iOq+/vUlbnq+0lNmevzPaK6Y/X9O6zK4BWKR48ejePHK66TTZ8+HStXroSZmRkiIyMRHR39cCmIiIiI6ojBPTeRkZHqfwcEBODs2bP47bff8Nhjj6F7d16TJCIiInEZ1HNz//59BAQE4Ny5c+q29u3b44UXXmBhQ0RERJJgUHHTpEkTnDp1SufGmURERERSYPCYm9DQUHzxxRf1kYWIiIjokRk85qakpATr1q1DfHw8fH190bTKUOaYmJg6C0dERERkKIOLm1OnTuHxxx8HAI2xNwB4uYqIiIhEZ3Bxk5iYWB85iIiIiOqEwWNuiIiIiKSMxQ0REREpCosbIiIiUhTRi5uVK1fC1dUV5ubm8PHxweHDh/V6XkpKCkxMTNCjR4/6DUhERESyYvAKxaNHj8aFCxfq5IvHxcUhIiICM2bMQEZGBnr37o0hQ4YgOzu7xufdvHkToaGhGDBgQJ3kICIiIuUweIXiXbt21dkXj4mJQVhYGMaOHQtPT0/ExsbCyckJq1atqvF5b7/9NkJCQtCrV686y0JERETKYPBlqaCgIOzevfuRv3BJSQnS0tIQGBio0R4YGIjU1NRqn7dhwwacP38es2bN0uvrFBcXo7CwUONGREREymXwOjfu7u6YN28eUlNT4ePjo7VC8cSJE/V6nfz8fJSVlcHBwUGj3cHBAVevXtX5nMzMTEybNg2HDx+GiYl+0RctWoQ5c+bodSwRERHJn8HFzbp162BjY4O0tDSkpaVpPKZSqfQubh58zoMEQdC50nFZWRlCQkIwZ84cdOzYUe/Xnz59OqKiotT3CwsL4eTkZFBGIiIikg+Di5usrKw6+cItW7aEsbGxVi9NXl6eVm8OANy6dQu//fYbMjIyMH78eABAeXk5BEGAiYkJ9u/fj/79+2s9z8zMDGZmZnWSmYiIiKTvkaaCC4IAQRAe6rmmpqbw8fFBfHy8Rnt8fDz8/Py0jm/evDlOnjyJY8eOqW/h4eHw8PDAsWPH8NRTTz1UDiIiIlKWhypuNm/ejK5du8LCwgIWFhbo1q0bvvzyS4NfJyoqCuvWrcP69etx5swZREZGIjs7G+Hh4QAqLimFhoZWBDUyQpcuXTRurVq1grm5Obp06aI19oeIiIgaJ4MvS8XExGDmzJkYP348/P39IQgCUlJSEB4ejvz8fERGRur9WsHBwSgoKMDcuXORm5uLLl26YM+ePXB2dgYA5Obm1rrmDREREdGDDC5uPv30U6xatUrdowIAI0aMQOfOnTF79myDihsAGDduHMaNG6fzsY0bN9b43NmzZ2P27NkGfT0iIiJSNoMvS+Xm5uocE+Pn54fc3Nw6CUVERET0sAwubtzd3bFt2zat9ri4OHTo0KFOQhERERE9LIMvS82ZMwfBwcE4dOgQ/P39oVKpkJycjAMHDugseoiIiIgaksE9Ny+++CKOHj2Kli1bYvfu3di5cydatmyJo0ePIigoqD4yEhEREenNoJ6b+/fv46233sLMmTOxZcuW+spERERE9NBE3RWciIiIqK6Jtis4ERERUX0QbVdwIiIiovog+q7gRERERHXJoOJGEAQkJiaiVatWsLS0rK9MRERERA/NoDE3giCgY8eOuHz5cn3lISIiInokBhU3RkZG6NChAwoKCuorDxEREdEjMXi21Mcff4zo6GicOnWqPvIQERERPRKDBxS//vrrKCoqQvfu3WFqagoLCwuNx69fv15n4YiIiIgMZXBxExsbWw8xiIiIiOqGwcXNG2+8UR85iIiIiOqEwWNuAOD8+fN4//338eqrryIvLw8AsHfvXvz+++91Go6IiIjIUAYXN0lJSejatSt+/fVX7Ny5E7dv3wYAnDhxArNmzarzgERERESGMLi4mTZtGubPn4/4+HiYmpqq2wMCAnDkyJE6DUdERERkKIOLm5MnTyIoKEir3d7enuvfEBERkegMLm5sbGyQm5ur1Z6RkQFHR8c6CUVERET0sAwubkJCQvDuu+/i6tWrUKlUKC8vR0pKCqZMmYLQ0ND6yEhERESkN4OLmwULFqB9+/ZwdHTE7du34eXlhT59+sDPzw/vv/9+fWQkIiIi0pvB69w0adIEX331FebNm4f09HSUl5fD29sbHTp0qI98RERERAYxuLip5ObmBjc3t7rMQkRERPTIHmoRPyIiIiKpYnFDREREisLihoiIiBSFxQ0REREpil4Dik+cOKH3C3br1u2hwxARERE9Kr2Kmx49ekClUkEQBKhUqhqPLSsrq5NgRERERA9Dr8tSWVlZuHDhArKysrBjxw64urpi5cqVyMjIQEZGBlauXInHHnsMO3bsqO+8RERERDXSq+fG2dlZ/e///Oc/WL58OYYOHapu69atG5ycnDBz5kw8//zzdR6SiIiISF8PtSu4q6urVrurqytOnz5dJ6GIiIiIHpbBxY2npyfmz5+Pe/fuqduKi4sxf/58eHp61mk4IiIiIkMZvP3C6tWrMWzYMDg5OaF79+4AgOPHj0OlUuGHH36o84BEREREhjC4uHnyySeRlZWFLVu24OzZsxAEAcHBwQgJCUHTpk3rIyMRERGR3h5q40xLS0u89dZbdZ2FiIiI6JE91ArFX375JZ5++mm0bdsWly5dAgAsW7YM3377bZ2GIyIiIjKUwcXNqlWrEBUVhSFDhuCff/5RL9pna2uL2NjYus5HREREZBCDi5tPP/0Un3/+OWbMmAETk3+vavn6+uLkyZN1Go6IiIjIUAYXN1lZWfD29tZqNzMzw507d+okFBEREdHDMri4cXV1xbFjx7Taf/rpJ3h5edVFJiIiIqKHZnBxEx0djXfeeQdxcXEQBAFHjx7FggUL8N577yE6OtrgACtXroSrqyvMzc3h4+ODw4cPV3tscnIy/P39YWdnBwsLC3Tq1AnLli0z+GsSERGRchk8FXz06NEoLS3F1KlTUVRUhJCQEDg6OuKTTz7BK6+8YtBrxcXFISIiAitXroS/vz/WrFmDIUOG4PTp02jfvr3W8U2bNsX48ePRrVs3NG3aFMnJyXj77bfRtGlTTk0nIiIiAA85FfzNN9/EpUuXkJeXh6tXryInJwdhYWEGv05MTAzCwsIwduxYeHp6IjY2Fk5OTli1apXO4729vfHqq6+ic+fOcHFxweuvv45BgwbV2NtDREREjctDDSjOzMwEALRs2RKtWrUCAGRmZuLixYt6v05JSQnS0tIQGBio0R4YGIjU1FS9XiMjIwOpqano27dvtccUFxejsLBQ40ZERETKZXBxM2rUKJ3Fx6+//opRo0bp/Tr5+fkoKyuDg4ODRruDgwOuXr1a43PbtWsHMzMz+Pr64p133sHYsWOrPXbRokWwtrZW35ycnPTOSERERPJjcHGTkZEBf39/rfaePXvqnEVVG5VKpXFfEASttqoOHz6M3377DatXr0ZsbCy2bt1a7bHTp0/HzZs31becnByDMxIREZF8GDygWKVS4datW1rtN2/eVK9WrI+WLVvC2NhYq5cmLy9PqzenKldXVwBA165dce3aNcyePRuvvvqqzmPNzMxgZmamdy4iIiKSN4N7bnr37o1FixZpFDJlZWVYtGgRnn76ab1fx9TUFD4+PoiPj9doj4+Ph5+fn96vIwgCiouL9T6eiIiIlM3gnpuPP/4Yffr0gYeHB3r37g2g4jJRYWEhEhISDHqtqKgojBw5Er6+vujVqxfWrl2L7OxshIeHA6i4pHT58mVs3rwZAPDZZ5+hffv26NSpE4CKdW+WLFmCCRMmGPptEBERkUIZXNx4eXnhxIkTWLFiBY4fPw4LCwuEhoZi/PjxaNGihUGvFRwcjIKCAsydOxe5ubno0qUL9uzZA2dnZwBAbm4usrOz1ceXl5dj+vTpyMrKgomJCR577DF8+OGHePvttw39NoiIiEihDC5uAKBt27ZYuHBhnQQYN24cxo0bp/OxjRs3atyfMGECe2mIiIioRg9V3Ny4cQNHjx5FXl4eysvLNR4LDQ2tk2BERERED8Pg4ub777/Ha6+9hjt37sDKykpj2rZKpWJxQ0RERKIyeLbU5MmTMWbMGNy6dQs3btzAP//8o75dv369PjISERER6c3g4uby5cuYOHEiLC0t6yMPERER0SMxuLgZNGgQfvvtt/rIQkRERPTIDB5z8+yzzyI6OhqnT59G165d0aRJE43Hhw8fXmfhiIiIiAxlcHHz5ptvAgDmzp2r9ZhKpTJoCwYiIiKiumZwcVN16jcRERGRlBg85oaIiIhIyh5qEb87d+4gKSkJ2dnZKCkp0Xhs4sSJdRKMiIiI6GEYXNxkZGRg6NChKCoqwp07d9CiRQvk5+fD0tISrVq1YnFDREREojL4slRkZCSGDRuG69evw8LCAr/88gsuXboEHx8fLFmypD4yEhEREenN4OLm2LFjmDx5MoyNjWFsbIzi4mI4OTnh448/xnvvvVcfGYmIiIj0ZnBx06RJE/V+Ug4ODsjOzgYAWFtbq/9NREREJBaDx9x4e3vjt99+Q8eOHREQEIAPPvgA+fn5+PLLL9G1a9f6yEhERESkN4N7bhYuXIg2bdoAAObNmwc7Ozv897//RV5eHtauXVvnAYmIiIgMYXDPja+vr/rf9vb22LNnT50GIiIiInoUXMSPiIiIFEWvnhtvb2/1IOLapKenP1IgIiIiokehV3Hz/PPP13MMIiIiorqhV3Eza9as+s5BREREVCc45oaIiIgUxeDZUmVlZVi2bBm2bdumc+PM69ev11k4IiIiIkMZ3HMzZ84cxMTE4OWXX8bNmzcRFRWFF154AUZGRpg9e3Y9RCQiIiLSn8HFzVdffYXPP/8cU6ZMgYmJCV599VWsW7cOH3zwAX755Zf6yEhERESkN4OLm6tXr6q3WWjWrBlu3rwJAHjuuefw448/1m06IiIiIgMZXNy0a9cOubm5AAB3d3fs378fAPB///d/MDMzq9t0RERERAYyuLgJCgrCgQMHAACTJk3CzJkz0aFDB4SGhmLMmDF1HpCIiIjIEAbPlvrwww/V/37ppZfQrl07pKamwt3dHcOHD6/TcERERESGMri4qapnz57o2bNnXWQhIiIiemQGFzcFBQWws7MDAOTk5ODzzz/H3bt3MXz4cPTu3bvOAxIREREZQu8xNydPnoSLiwtatWqFTp064dixY3jiiSewbNkyrF27FgEBAdi9e3c9RiUiIiKqnd7FzdSpU9G1a1ckJSWhX79+eO655zB06FDcvHkT//zzD95++22N8ThEREREYtD7stT//d//ISEhAd26dUOPHj2wdu1ajBs3DkZGFfXRhAkTOPaGiIiIRKd3z83169fRunVrABWL9zVt2hQtWrRQP25ra4tbt27VfUIiIiIiAxi0zo1KparxPhEREZHYDJotNWrUKPUqxPfu3UN4eDiaNm0KACguLq77dEREREQG0ru4eeONNzTuv/7661rHhIaGPnoiIiIiokegd3GzYcOG+sxBREREVCcM3luKiIiISMpY3BAREZGisLghIiIiRWFxQ0RERIoienGzcuVKuLq6wtzcHD4+Pjh8+HC1x+7cuRPPPPMM7O3t0bx5c/Tq1Qv79u1rwLREREQkdaIWN3FxcYiIiMCMGTOQkZGB3r17Y8iQIcjOztZ5/KFDh/DMM89gz549SEtLQ0BAAIYNG4aMjIwGTk5ERERSJWpxExMTg7CwMIwdOxaenp6IjY2Fk5MTVq1apfP42NhYTJ06FU888QQ6dOiAhQsXokOHDvj+++8bODkRERFJlWjFTUlJCdLS0hAYGKjRHhgYiNTUVL1eo7y8HLdu3dLY46qq4uJiFBYWatyIiIhIuUQrbvLz81FWVgYHBweNdgcHB1y9elWv11i6dCnu3LmDl19+udpjFi1aBGtra/XNycnpkXITERGRtIk+oLjq5puCIOi1IefWrVsxe/ZsxMXFoVWrVtUeN336dNy8eVN9y8nJeeTMREREJF0GbZxZl1q2bAljY2OtXpq8vDyt3pyq4uLiEBYWhm+++QYDBw6s8VgzMzP1Zp9ERESkfKL13JiamsLHxwfx8fEa7fHx8fDz86v2eVu3bsWoUaPw9ddf49lnn63vmERERCQzovXcAEBUVBRGjhwJX19f9OrVC2vXrkV2djbCw8MBVFxSunz5MjZv3gygorAJDQ3FJ598gp49e6p7fSwsLGBtbS3a90FERETSIWpxExwcjIKCAsydOxe5ubno0qUL9uzZA2dnZwBAbm6uxpo3a9asQWlpKd555x2888476vY33ngDGzdubOj4REREJEGiFjcAMG7cOIwbN07nY1ULloMHD9Z/ICIiIpI10WdLEREREdUlFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFEL25WrlwJV1dXmJubw8fHB4cPH6722NzcXISEhMDDwwNGRkaIiIhouKBEREQkC6IWN3FxcYiIiMCMGTOQkZGB3r17Y8iQIcjOztZ5fHFxMezt7TFjxgx07969gdMSERGRHIha3MTExCAsLAxjx46Fp6cnYmNj4eTkhFWrVuk83sXFBZ988glCQ0NhbW3dwGmJiIhIDkQrbkpKSpCWlobAwECN9sDAQKSmptbZ1ykuLkZhYaHGjYiIiJRLtOImPz8fZWVlcHBw0Gh3cHDA1atX6+zrLFq0CNbW1uqbk5NTnb02ERERSY/oA4pVKpXGfUEQtNoexfTp03Hz5k31LScnp85em4iIiKTHRKwv3LJlSxgbG2v10uTl5Wn15jwKMzMzmJmZ1dnrERERkbSJ1nNjamoKHx8fxMfHa7THx8fDz89PpFREREQkd6L13ABAVFQURo4cCV9fX/Tq1Qtr165FdnY2wsPDAVRcUrp8+TI2b96sfs6xY8cAALdv38bff/+NY8eOwdTUFF5eXmJ8C0RERCQxohY3wcHBKCgowNy5c5Gbm4suXbpgz549cHZ2BlCxaF/VNW+8vb3V/05LS8PXX38NZ2dnXLx4sSGjExERkUSJWtwAwLhx4zBu3Didj23cuFGrTRCEek5EREREcib6bCkiIiKiusTihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpiujFzcqVK+Hq6gpzc3P4+Pjg8OHDNR6flJQEHx8fmJubw83NDatXr26gpERERCQHohY3cXFxiIiIwIwZM5CRkYHevXtjyJAhyM7O1nl8VlYWhg4dit69eyMjIwPvvfceJk6ciB07djRwciIiIpIqUYubmJgYhIWFYezYsfD09ERsbCycnJywatUqncevXr0a7du3R2xsLDw9PTF27FiMGTMGS5YsaeDkREREJFWiFTclJSVIS0tDYGCgRntgYCBSU1N1PufIkSNaxw8aNAi//fYb7t+/X29ZiYiISD5MxPrC+fn5KCsrg4ODg0a7g4MDrl69qvM5V69e1Xl8aWkp8vPz0aZNG63nFBcXo7i4WH3/5s2bAIDCwkKN48qK7z7U91FfqubThZkfHTM3DGZuOHLMzcwNQ+6ZK/8tCELtTxREcvnyZQGAkJqaqtE+f/58wcPDQ+dzOnToICxcuFCjLTk5WQAg5Obm6nzOrFmzBAC88cYbb7zxxpsCbjk5ObXWGKL13LRs2RLGxsZavTR5eXlavTOVWrdurfN4ExMT2NnZ6XzO9OnTERUVpb5fXl6O69evw87ODiqV6hG/C02FhYVwcnJCTk4OmjdvXqevXV+YuWEwc8Ng5oYjx9zM3DDqK7MgCLh16xbatm1b67GiFTempqbw8fFBfHw8goKC1O3x8fEYMWKEzuf06tUL33//vUbb/v374evriyZNmuh8jpmZGczMzDTabGxsHi18LZo3by6bX8JKzNwwmLlhMHPDkWNuZm4Y9ZHZ2tpar+NEnS0VFRWFdevWYf369Thz5gwiIyORnZ2N8PBwABW9LqGhoerjw8PDcenSJURFReHMmTNYv349vvjiC0yZMkWsb4GIiIgkRrSeGwAIDg5GQUEB5s6di9zcXHTp0gV79uyBs7MzACA3N1djzRtXV1fs2bMHkZGR+Oyzz9C2bVssX74cL774oljfAhEREUmMqMUNAIwbNw7jxo3T+djGjRu12vr27Yv09PR6TvVwzMzMMGvWLK3LYFLGzA2DmRsGMzccOeZm5oYhhcwqQdBnThURERGRPIi+txQRERFRXWJxQ0RERIrC4oaIiIgMos9qx2JicUNEsnT//n24ubnh9OnTYkfRW2lpKUxMTHDq1CmxozQqf/75J/bt24e7dyu2FpDrUNOioiKxI6jZ2toiLy8PANC/f3/cuHFD3EBViD5bisRRUlKCvLw8lJeXa7S3b99epEQ1O3z4MNasWYPz589j+/btcHR0xJdffglXV1c8/fTTYsfT6csvv8Tq1auRlZWFI0eOwNnZGbGxsXB1da12oUrSX5MmTVBcXFznK43XJxMTEzg7O6OsrEzsKAYLCgrS+bNWqVQwNzeHu7s7QkJC4OHhIUI63QoKChAcHIyEhASoVCpkZmbCzc0NY8eOhY2NDZYuXSp2RC39+vXDli1b0K5dO432X3/9FSNHjsS5c+dESqapWbNmKCgoQKtWrXDw4EHJbV7Nnps6UFpaip9//hlr1qzBrVu3AABXrlzB7du3RU6mLTMzE71794aFhQWcnZ3h6uoKV1dXuLi4wNXVVex4Ou3YsQODBg2ChYUFMjIy1Buh3rp1CwsXLhQ5nW6rVq1CVFQUhg4dihs3bqhPZjY2NoiNjRU33ANsbW3RokULvW5SNGHCBHz00UcoLS0VO4re3n//fUyfPh3Xr18XO4pBrK2tkZCQgPT0dHWRk5GRgYSEBJSWliIuLg7du3dHSkqKyEn/FRkZCRMTE2RnZ8PS0lLdHhwcjL1794qYrHrNmzdHt27d8L///Q9AxZZBs2fPRp8+fTB8+HCR0/1r4MCBCAgIQEBAAICK4rd///46b2LgVPBHdOnSJQwePBjZ2dkoLi7GuXPn4ObmhoiICNy7dw+rV68WO6IGf39/mJiYYNq0aWjTpo3WJ7Hu3buLlKx63t7eiIyMRGhoKKysrHD8+HG4ubnh2LFjGDx4cLW7yIvJy8sLCxcuxPPPP6+R+dSpU+jXrx/y8/PFjggA2LRpk97HvvHGG/WY5OEEBQXhwIEDaNasGbp27YqmTZtqPL5z506RklXP29sbf/75J+7fvw9nZ2etzFJdx2vatGkoLCzEihUrYGRU8bm4vLwckyZNgpWVFRYsWIDw8HD8/vvvSE5OFjlthdatW2Pfvn3o3r27xt9hVlYWunbtKskPoACwevVqTJkyBcOHD8fFixeRnZ2NjRs3YuDAgWJHU7t79y42bdqE8+fPY+nSpXjzzTc1CsgHLVu2rIHT8bLUI5s0aRJ8fX1x/Phxjc07g4KCMHbsWBGT6Xbs2DGkpaWhU6dOYkfR2x9//IE+ffpotTdv3lxy13krZWVlwdvbW6vdzMwMd+7cESGRblIsWAxhY2MjuxXKn3/+ebEjPJQvvvgCKSkp6sIGAIyMjDBhwgT4+flh4cKFGD9+PHr37i1iSk137tzRecLNz8+X9KJ4lVsNffTRRzAxMcHBgwfh5+cndiwNFhYW6q2SfvvtN3z00Uf1vm+jIVjcPKLk5GSkpKTA1NRUo93Z2RmXL18WKVX1vLy8JNNroK82bdrgzz//hIuLi0Z7cnIy3NzcxAlVC1dXVxw7dky9lUiln376CV5eXiKl0mbIjAcpbtq3YcMGsSMYbNasWWJHeCilpaU4e/YsOnbsqNF+9uxZ9WVXc3NzSY2B6tOnDzZv3ox58+YBqBgfVF5ejsWLF6svp0jNP//8g7Fjx+LAgQNYs2YNkpKSEBgYiI8//rja1fzFdP/+fVy6dAlXrlxhcaMk5eXlOgcH/vXXX7CyshIhUc0++ugjTJ06FQsXLkTXrl21dlOX4gns7bffxqRJk7B+/XqoVCpcuXIFR44cwZQpU/DBBx+IHU+n6OhovPPOO7h37x4EQcDRo0exdetWLFq0COvWrRM7npqNjU2tJyNBEKBSqSQ7CLa0tBQHDx7E+fPnERISAisrK1y5cgXNmzdHs2bNxI6n040bN7B9+3acP38e0dHRaNGiBdLT0+Hg4ABHR0ex4+k0cuRIhIWF4b333sMTTzwBlUqFo0ePYuHCheoNjpOSktC5c2eRk/5r8eLF6NevH3777TeUlJRg6tSp+P3333H9+nVJjQ16UJcuXeDq6oqMjAy4urrizTffRFxcHMaNG4cff/wRP/74o9gRNUh1YD/H3Dyi4OBgWFtbY+3atbCyssKJEydgb2+PESNGoH379pL7ZFnZpVz1F1HqJ7AZM2Zg2bJluHfvHoCKyztTpkxRfyKTos8//xzz589HTk4OAMDR0RGzZ89GWFiYyMn+lZSUpPexffv2rcckD0duY94A4MSJExg4cCCsra1x8eJF/PHHH3Bzc8PMmTNx6dIlbN68WeyIOpWVleHDDz/EihUrcO3aNQCAg4MDJkyYgHfffRfGxsbIzs6GkZGR1kwfMV29ehWrVq1CWloaysvL8fjjj+Odd95BmzZtxI6m07x58zBjxgyNy39AxQfm0aNHIz4+XqRk1fvwww9x9uxZrFu3DiYm0ugzYXHziK5cuYKAgAAYGxsjMzMTvr6+yMzMRMuWLXHo0CG0atVK7IgaajuZSfEEVqmoqAinT59GeXk5vLy8JPupvKr8/HyUl5dL7ndBCSoHbH/xxRews7NTDxhNSkrC2LFjkZmZKXZELQMHDsTjjz+Ojz/+WGOQa2pqKkJCQnDx4kWxI9aq8nKmFHt6K92/fx+BgYFYs2aN1qU0qltSHNgvjRJLxtq2bYtjx47hf//7n/qTQVhYGF577TVYWFiIHU+LlIuX6owZMwaffPIJrKys4Ovrq26/c+cOJkyYgPXr14uYTrf+/ftj586dsLGxQcuWLdXthYWFeP7555GQkCBiupoVFRUhOzsbJSUlGu3dunUTKVH15DbmDQD+7//+D2vWrNFqd3R0lOTMP12kXNRUatKkCU6dOiW5yyX6ktPfoRQH9rPnppGS0x+OsbExcnNztXo+8vPz0bp1a0mucWJkZISrV69qZc7Ly4Ojo6PkFrwCgL///hujR4/GTz/9pPNxKV6ybNGiBZKTk+Hl5aXRC5KcnIwXX3xRfflEShwcHLB37154e3trZN6/fz/CwsLUlzGl5tq1a5gyZQoOHDiAvLw8rVV+pfj7MXnyZDRp0gQffvih2FH0Jse/Qyliz80j2rRpE1q2bIlnn30WADB16lSsXbsWXl5e2Lp1q9ZsGbHJ6Q+nsLAQgiBAEATcunUL5ubm6sfKysqwZ88eyV3qOXHihPrfp0+f1vgkXlZWhr1790p2wGhERAT++ecf/PLLLwgICMCuXbtw7do1zJ8/X5IruQLAM888g9jYWKxduxZAxViy27dvY9asWRg6dKjI6XQbMWIE5s6di23btgGoyJydnY1p06ZJ7tPvg0aNGoXs7GzMnDlT5xpZUlRSUoJ169YhPj4evr6+WpdLYmJiREpWPTn+HX7++efo168fOnToIHaUfwn0SDp27CgcOHBAEARBSE1NFSwsLIQ1a9YIw4YNE4KCgkROpy0kJETw8/MTjh49KjRt2lTYv3+/8OWXXwoeHh7CDz/8IHY8DSqVSjAyMqr2ZmxsLMyfP1/smBoezKxSqbRulpaWwhdffCF2TJ1at24t/Prrr4IgCIKVlZXwxx9/CIIgCN9++63g7+8vZrRqXb58WejYsaPg6ekpmJiYCD179hTs7OwEDw8P4dq1a2LH0+nmzZuCv7+/YGNjIxgbGwtOTk5CkyZNhD59+gi3b98WO161mjVrJmRkZIgdwyD9+vWr9hYQECB2PJ3k+Hfo4eEhqFQqoU2bNsIrr7wirF69Wjhz5oyomdhz84hycnLg7u4OANi9ezdeeuklvPXWW/D390e/fv3EDadDQkICvv32WzzxxBMwMjKCs7MznnnmGTRv3hyLFi1S90BJQWJiIgRBQP/+/bFjxw6NLQBMTU3h7OyMtm3biphQW1ZWFgRBgJubG44ePQp7e3v1Y6ampmjVqhWMjY1FTFi9O3fuqHvCWrRogb///hsdO3ZE165dJbtqbuWYt61btyI9PV3yY96AivEqycnJ6q0MKmfwSGn1WV2cnJxkt+FkYmKi2BEMJse/w7Nnz+Lq1atITExEUlISli1bhnHjxsHe3h79+vVTbyXRoEQtrRTA3t5eSE9PFwRBEHr06CFs2rRJEARB+PPPP4WmTZuKGU0nKysrISsrSxAEQXB2dhaSk5MFQRCECxcuCBYWFiImq97FixeFsrIysWMonq+vr7B3715BEARhxIgRwsiRI4W//vpLmDp1quDm5iZyOuXYtGmTcO/ePa324uJi9fuHFO3bt08IDAxUv3/ITXZ2tpCTkyN2jFrJ/e/w9u3bwt69e4VRo0YJJiYmgrGxsSg5OKD4Eb322ms4e/YsvL29sXXrVmRnZ8POzg7fffcd3nvvPZw6dUrsiBqeeOIJzJ8/H4MGDcLzzz+v7rFZvny5elExqZLTIOhKp0+f1plZShvgVfrqq69w//59jBo1ChkZGRg0aBAKCgpgamqKjRs3Ijg4WOyIOl2+fBkpKSk6d7mfOHGiSKmqV90A+codlqU07u1Btra2KCoqQmlpKSwtLbUWAJXiRqClpaWYM2cOli9frt5HqlmzZpgwYQJmzZql9T1IgRz/Dn/66SckJSXh4MGDOH78ODp37ow+ffqgX79+6N27N2xtbRs8E4ubR3Tjxg28//77yMnJwX//+18MHjwYQMUS66amppgxY4bICTXJ8Q9HToOgK124cAFBQUE4efIkVCqVuju/chCmlDInJCSgT58+WotvFRUV4ezZs2jfvr3GdHYp2bBhA8LDw2Fqago7OzuNQa4qlQoXLlwQMZ1uRkZGuHbtmsYlSwA4fvw4AgICJFkkALVvsirFfcrCw8Oxa9cuzJ07F7169QIAHDlyBLNnz8aIESMkuchjVXL4OzQyMoK9vT0mT56Mt99+G9bW1mJHYnHT2MnhD+e1117DxYsXERsbq3P2gJTGCVUaNmwYjI2N8fnnn6vH3xQUFGDy5MlYsmSJpDYXrNqT0LNnT+zYsUOys7oe5OTkhPDwcEyfPl1rRVep8fb2hkqlUn+yfbCYLCsrQ1ZWFgYPHqyeRUWPztraGv/73/8wZMgQjfaffvoJr7zyCm7evClSMmWJjY3FoUOHcPjwYRgbG6Nv377o168f+vXrB09PT1EycUBxHZHjJRMAsLS0xOOPPy52jBrJaRB0pSNHjiAhIQH29vYwMjKCkZERnn76aSxatAgTJ05ERkaG2BHVqn6++f3331FcXCxSGsMUFRXhlVdekXxhA/y7G/ixY8cwaNAgjRW2TU1N4eLiIrmp4IWFheoF+2rbZFWKC/uZm5trbbgLAC4uLloLP0qFIAjYvn07EhMTdV5qFWO139pEREQgIiICAHDy5EkkJSXh559/xqRJk2BnZ4fc3NwGz8Ti5hH9/fffGDVqFPbu3avzcSlcfoiKisK8efPQtGlTREVF1XisFNd9kOPsgbKyMvXJq2XLlrhy5Qo8PDzg7OyMP/74Q+R0yhEWFoZvvvkG06ZNEztKrSp3A3dxcUFwcLDGuk1SZWtrq+7Vq26TVUHC+9K98847mDdvHjZs2AAzMzMAQHFxMRYsWIDx48eLnE63SZMmYe3atQgICICDg4Ms1hOqlJGRgYMHDyIxMRGHDx9GeXm5aPuMsbh5RBEREbhx44akF1zKyMhQr4hbU4+BVP+IPDw88Mcff8DFxQU9evTAmjVr4OLigtWrV0t287suXbrgxIkTcHNzw1NPPYWPP/4YpqamWLt2Ldzc3MSOp0GlUmmNVZHq70JVixYtwnPPPYe9e/fq3OVeisV65diUkpISnZ/M27dvL0YsnRISEtRLMMhxWnVGRgYOHDiAdu3aoXv37gAqxjaVlJRgwIABeOGFF9THSqVHZMuWLdi5c6dkF6HUZfjw4UhOTkZhYSF69OiBfv364a233kKfPn1E69FjcfOI5HDJ5ME3JTm+QUVERKi7NWfNmoVBgwbhq6++Ug+ClqL3338fd+7cAQDMnz8fzz33HHr37g07OzvExcWJnE6TIAgYMGCAegxIUVERhg0bptVtL8VesoULF2Lfvn3w8PAAAK0iTYoyMzMxZswYpKamarRLsQekci+60tJSHDx4EGPGjIGTk5PIqfSna88jqee3traW3Aeg2nTs2FH0YqYqDih+RM2bN8eJEyfg4uICFxcXfPXVV/D390dWVhY6d+6MoqIisSMqjhwGQety/fp12NraSu6kO2fOHL2Oq7ysIiW2trZYtmwZRo0aJXYUvfn7+8PExATTpk3TuY1BZQ+D1FhZWeHkyZM6x7BQ3dm0aRP27t2L9evXS3YhSn3cuHEDNjY2on199tw8IjlcMnmw67U2UumarYkcBkHr8uAKy1IixaJFX2ZmZvD39xc7hkGOHTuGtLQ0dOrUSewoBhkwYAAOHjwoq0JSjv7zn/9g69ataNWqFVxcXLQutUqxB/Wjjz5SjyUDgJdffhnbt29HmzZtsGfPHlEKdhY3j0jXJZMtW7bA1NS01nUhGsqDaw4IgoBdu3bB2toavr6+AIC0tDTcuHHDoCKoIclx9sC9e/fw6aefVptZim9QcjRp0iR8+umnWL58udhR9Obl5YX8/HyxYxhsyJAhmD59Ok6dOgUfHx+tTSiluDClHI0aNQppaWl4/fXXZTOgeM2aNdiyZQsAID4+HvHx8di7dy+2bduG6Oho7N+/v8Ez8bJUHRIEAXfv3pX0JZN3330X169fx+rVq9V7HJWVlWHcuHFo3rw5Fi9eLHJCbRMnTqxx9sCGDRtESla9kJAQxMfH46WXXtKZWc69JVISFBSEhIQE2NnZoXPnzlqfcqVY+CYkJOD999/HwoULdQ6ClsqYhapqmm4vtbFCcta0aVPs27cPTz/9tNhR9GZhYYFz587ByckJkyZNwr1797BmzRqcO3cOTz31FP75558Gz8Tipg588cUXWLZsGTIzMwEAHTp0QEREBMaOHStyMm329vZITk5WD8Cs9Mcff8DPzw8FBQUiJateixYtsGXLFlnNHrC2tsaePXtkd8lEbkaPHl3j41IsfCuLhKoFrxQHFFPD69SpE7Zt2yb5NdIe1LZtW2zfvh1+fn7w8PDA/Pnz8Z///Ad//PEHnnjiiVrXSKoPvCz1iGbOnIlly5ZhwoQJGst7R0ZG4uLFi5g/f77ICTWVlpbizJkzWsXNmTNntC6dSIUcZw84OjrCyspK7BiKJ8XipTZynLFIDWfp0qWYOnUqVq9eLZvB2y+88AJCQkLQoUMHFBQUqFeEPnbsGNzd3cUJ1ZC7dCqRnZ2d8PXXX2u1f/3114KdnZ0IiWoWGRkp2NraCosXLxYOHz4sHD58WFi8eLFgZ2cnREZGih1Pp40bNwqvvPKKUFRUJHYUve3Zs0cYPHiwcPHiRbGjENWZn3/+WXj22WcFNzc34bHHHhOeffZZIT4+XuxYNZJbZhsbG8HU1FQwMjISmjVrJtja2mrcpKikpERYvHixMHHiRCE9PV3dvmzZMuHzzz8XJRN7bh5RWVmZemDug3x8fFBaWipCopotWbIErVu3xrJly9QDodu0aYOpU6di8uTJIqfTTY6zB3x9fXHv3j24ubnJZgdlADhw4ACWLVuGM2fOQKVSoVOnToiIiMDAgQPFjqZTQUEBPvjgg2oHbkvl53zixAl06dIFRkZGOHHiRI3HSvVyxIoVKxAZGYmXXnoJkyZNAgD88ssvGDp0KGJiYiS54q8cMy9btkwWg4gfdOTIEURERGhtvjt+/Hit9ZwaCsfcPKIJEyagSZMmWiuhTpkyBXfv3sVnn30mUrLaVV4HleoAxkovv/wyEhMTZTU4d+DAgcjOzkZYWJjOzFLcQfnBE0HlJdZffvkF27dvl+yJYMiQITh//rzkf85GRka4evUqWrVqBSMjI42d4h8k5TE3jo6OmD59utbvwWeffYYFCxbgypUrIiWrnhwzy1HVzXcrFRQUoFWrVqL8TrO4eQgP7s9UWlqKjRs3on379ujZsyeAihNCTk4OQkND8emnn4oVs1qVq42eP38eISEhsLKywpUrV9C8eXONzfykQo6zBywtLXHkyBHJLsimixxPBFZWVkhOTpb8z/nSpUto3749VCoVLl26VOOxzs7ODZTKMFZWVsjIyNAaQ5GZmQlvb2/cvn1bpGTVk2NmKRYKtTEyMsK1a9dgb2+v0X7u3Dn4+vpyQLFcVN2fycfHBwBw/vx5ABUzkuzt7fH77783eLbaXLp0CYMHD0Z2djaKi4vxzDPPwMrKCh9//DHu3buH1atXix1Ri5OTk+R7l6rq1KkT7t69K3YMgxQWFmLw4MFa7YGBgXj33XdFSFQ7ufycnZ2d8fPPP8Pf31+yxUtthg8fjl27diE6Olqj/dtvv8WwYcNESlUzOWaurr+huLhYcjuZV66NplKpMGrUKPXmpEDFkI0TJ07Az89PlGwsbh6CnGc7TJo0Cb6+vjh+/Djs7OzU7UFBQZKcug7Ic/bAhx9+iMmTJ2PBggWyWctEjieClStXYtq0afjggw/QpUsXSf+cAwMDYWpqiieffBIBAQEICAiAn5+f5E5Y1fH09MSCBQtw8OBBjcuWKSkpmDx5ssZCihMnThQrpgY5Za7MolKpsG7dOo1e9LKyMhw6dEhyq1pXLhArCAKsrKw0toswNTVFz5498eabb4qSjZelGpmWLVsiJSUFHh4esLKywvHjx+Hm5oaLFy/Cy8tLknth2draoqioCKWlpbIZnCvHtUzmz5+PJUuWwN/fX+eJ4MFCQewTQaXMzEy8+uqrWr2pUvw5X758GQkJCUhKSkJiYiKysrJgbm6OXr16qYudp556SmtQplS4urrqdZxKpcKFCxfqOY1+5JS5MuulS5fQrl079SKrQEWh4OLigrlz5+Kpp54SK2K15syZgylTpmitWi0mFjeNTIsWLZCcnAwvLy+N4iY5ORkvvvgirl27JnZELbVtYyGVQaMPSkpKqvHxyt2WpUROJ4JKTz75JExMTDBp0iSdA4ql+HOulJOTg8TERBw8eBAHDx7EpUuXYGlpiVu3bokdjUQUEBCAnTt3wtbWVuwossbippEJDg6GtbU11q5dCysrK5w4cQL29vYYMWIE2rdvL8tF0ajxsrS0REZGhtailHJx/vx5JCQk4ODBg/jhhx9QVlYmyUGuupSWluLevXuSnISgS+WpTm7TrOnhsLhpZK5cuYKAgAAYGxsjMzMTvr6+yMzMRMuWLXHo0CGtEfpiKSwsVF8GqW2kvVTGVShhLZNKcjkR9OnTBx988IFk1+Gp6sKFCzh48CASExORmJiIW7duwc/PD3369EHfvn3xxBNPaF12FduePXtQUFCAkSNHqtsWLFiAefPmobS0FP3790dcXJxkexo2b96MxYsXq7fH6dixI6KjozW+H7FlZ2c/1PNsbGwk8/4nNSxuGqG7d+9i69atSE9PR3l5OR5//HG89tprGoPBxPbgdMjKdUGqktq4CiWsZSKHE8GDvvnmG8yePRvR0dE6B25LqYh0dnZGYWEhnn76aXUx4+PjozG2Qor69++PF198Ee+88w4AIDU1Fb1798bcuXPh6emJGTNmYMiQIVprfUlBTEwMZs6cifHjx8Pf3x+CICAlJQWfffYZ5s+fj8jISLEjAkCN7xfVUalUmDVrFj744IN6TCZfLG5IkpKSkuDv7w8TExPZjF+R+1omcjkRPEjXTtWVJwmpFZGtW7dGcXExevfujX79+qFv3754/PHHJd871qpVK+zbtw/e3t4AKtb5On36NPbu3Qugomdn0qRJ6oJYSlxdXTFnzhyEhoZqtG/atAmzZ89GVlaWSMmovrG4aYQuX76MlJQUncvVS2UWDDU8OZ4I5FZEnj17Vn1ZKikpCffu3cPTTz+tLnZ8fHx0FmxisrCwwB9//IH27dsDqBjE/dJLL2Hq1KkAKv4PvLy8cOfOHTFj6mRubo5Tp07pXMSva9euuHfvnkjJlEdqW7ewuGlkNmzYgPDwcJiamsLOzk7jU6OUZsHUNmblQVK59PDdd9/pfezw4cPrMcnD4Ymg4Z05c0Y9Y2rfvn1QqVS4ceOG2LE0PPbYY1i5ciUGDRqE27dvw87ODgkJCfD39wdQsbfboEGD8Pfff4ucVFuXLl0QEhKC9957T6N9/vz5iIuLw8mTJ0VKVruSkhKdH0Ari0wpkeLWLSxuGhknJyeEh4dj+vTpkvuE+CB9r0FL6dKDvj9PKWV+kBxPBJs3b67x8aq9UFJy7do1jcHFmZmZMDMzk9yKy++++y6+++47vPfee9izZw9SU1Nx4cIF9VihtWvXYvPmzUhOThY5qbYdO3YgODgYAwcOhL+/P1QqFZKTk3HgwAFs27YNQUFBYkfUkpmZiTFjxmhtOCnFS62VpLh1C4ubRsbOzg5Hjx7FY489JnaUGtV2ueFBUrv0IFdyPBFUnaFz//59FBUVwdTUFJaWlpJa4DEvL0+9pk1iYiLOnTuHJk2aaKxY3KtXL40l7KWgqKgIb7/9Nn744Qe0bt0aa9euRe/evdWPBwQEYPDgwZLdoiM9PR0xMTE4c+YMBEGAl5cXJk+erB5DJDWVYw2nTZuGNm3aaI3JkuI+alLcw4vFTSMzdepUtGjRAtOmTRM7CkmQ3E4EumRmZuK///0voqOjMWjQILHjqBkZGaFJkybw9fVFQEAA+vXrB39/f0nNUlSS+/fv46233sLMmTPh5uYmdhy9NW3aFGlpaZLbaqEmr732Gnr06KG1dcuSJUuQlpaGrVu3NngmFjeNTFlZGZ577jncvXtX59RZKU7nXLRoERwcHDBmzBiN9vXr1+Pvv/+W5CfGiRMnwt3dXWuA9ooVK/Dnn38iNjZWnGDVkOuJoDq//fYbXn/9dZw9e1bsKGqVO9tLaYl6pbOxsUF6erqsfqefeOIJLFu2DE8//bTYUfQmxa1bWNw0MvPmzcOsWbPg4eGhtVy9SqVCQkKCiOl0c3Fxwddff621u+yvv/6KV155RZKzeBwdHfHdd9+pd4yvlJ6ejuHDh+Ovv/4SKVn15HgiqE5GRgb69u1b6wKQpGyjR49G165dERUVJXYUvSUkJOD999/HwoULZbPprhS3bpHmDm1Ub2JiYrB+/XqMGjVK7Ch6u3r1Ktq0aaPVbm9vj9zcXBES1a6goEC9Y+6Dmjdvjvz8fBES1S4oKAi7d++W1Ymg6gw1QRCQm5uLFStWqGfzUOPl7u6OefPmITU1FT4+Plq9ZlJc+qJy6vSAAQM02qU8oFiKHzBZ3DQyZmZmsnvTd3JyQkpKitang5SUFLRt21akVDVzd3fH3r17tWYP/PTTT5LtGZHjieD555/XuK9SqWBvb4/+/ftj6dKl4oQiyVi3bh1sbGyQlpaGtLQ0jcdUKpUkf6cTExPFjvBIpLJ1C4ubRmbSpEn49NNPsXz5crGj6G3s2LGIiIjA/fv30b9/fwAVC0ZNnToVkydPFjmdblFRURg/fjz+/vtvjcxLly6V3HibSnI8EVRdA4ToQVLsUaiNVFZcN5TUtm7hmJtGJigoCAkJCbCzs0Pnzp21rufu3LlTpGTVEwQB06ZNw/Lly1FSUgKgYsG5d999V9L7qqxatUpjjQcXFxfMnj1b0muvyJ3cdqqWG6mtQqsUct90V4pbt7C4aWRGjx5d4+MbNmxooCSGu337Ns6cOQMLCwt06NBBcuuBVOfvv/+GhYUFT7h1SO47VcuxSJDiKrS6GDJmTCqzQ+W+6a4Ut25hcUOysnXrVgwfPpzTaeuIHE8EgLx3qpZLkVCVFFeh1SUgIEDjflpaGsrKyuDh4QEAOHfuHIyNjeHj4yOZ2aFy33RXklu3CEQyYmVlJZw/f17sGIrRr18/jZuVlZVgaWkpeHt7C97e3kLTpk2F5s2bCwEBAWJH1WBvby+kp6er70dGRgqDBg1S3//xxx8Fd3d3MaLVqm3btsKnn36q1b5ixQqhTZs2IiTST7NmzYTMzEyt9nPnzglNmzYVIVHtli5dKgwbNky4fv26uu369evCiBEjhCVLloiYTFk6d+4sLFiwQKt93rx5QpcuXURIJAgcUEyyIrCjsU49ODMjJiYGVlZW2LRpk/pyzj///IPRo0drLLcvBbdu3YKdnZ36fnJyMl566SX1/c6dO0umJ6GqwsJCDB48WKs9MDBQkgtSVho+fDh27dqltQrtt99+i2HDhomUqmZLly7F/v37NS5P2traYv78+QgMDJTshITLly8jJSVF58aZUhzYP2fOHAQHB+PQoUM6t24RA4sbIgIgrxNB27ZtcebMGbRv3x63b9/G8ePHsWzZMvXjBQUFsLS0FDFh9eRYJACAp6cnFixYgIMHD+pchfbBGZhSOQEXFhbi2rVr6Ny5s0Z7Xl4ebt26JVKqmm3YsAHh4eEwNTWFnZ2d1kKrUvnZPujFF1/E0aNHERMTg927d6u3bjl69KhoW7dwzA3JSnJyMnx9fWFubi52FMWxsrLCt99+q566XikhIQEjRoyQ1MlAzjtVS3Gpen1IcRXa2oSGhiIpKQlLly5Fz549AVT8rKOjo9GnTx9s2rRJ5ITanJycEB4ejunTp8PIyEjsOLWS6tYtLG6I6oncZsTI6UQg552q5VgkyFVRURGmTJmC9evX4/79+wAAExMThIWFYfHixZKcmGBnZ4ejR4/iscceEzuK3qS4dQuLm0ZIbifda9euYcqUKThw4ADy8vK0xt1IcWqkHGfEyPFEQOIQJLIKrb7u3LmD8+fPQxAEuLu7S/p3eerUqWjRogWmTZsmdhS9SXEPLxY3jYwcT7pDhgxBdnY2xo8fjzZt2mi9oY4YMUKkZNWTy7RZXeR0IpA7uRUJUluFVonKysrw3HPP4e7duzo3zpTi8gYLFizAkiVLMGDAAMls3cLippGR40nXysoKhw8fRo8ePcSOojcrKytkZGToXPfB29sbt2/fFikZSYEciwQprkKrRPPmzcOsWbPg4eEBBwcHrQHFUlmb50E1XWoV7fJqQ889J3HJca0KT09PjTVN5CAkJET4+OOPtdoXL14svPLKKyIkIqlYunSpYGlpKUydOlX49ttvhd27dwvR0dGCpaWlEBMTI3a8arm4uAibNm3Sat+4caPg4uIiQiJlsrGxETZs2CB2DNljz00j89prr6FHjx5a01CXLFmCtLQ0bN26VaRk1du/fz+WLl2KNWvWwMXFRew4epHrjBiqf1Jcql4fklyFVoFat26Nw4cPo0OHDmJHkTUWN42MHE+6tra2KCoqQmlpKSwtLbWuQV+/fl2kZNXjjBiqjlyLhC5duiAkJATvvfeeRvv8+fMRFxeHkydPipRMWRYtWoTc3FyNdYOkSOpbt7C4aWTkeNKtbQryG2+80UBJSIrkNvtPrkXCjh07EBwcjIEDB+pchTYoKEjsiIoQFBSEhIQE2NnZoXPnzlof5nbu3ClSMk1S38OLKxQ3MlLt8q6J3IsXQWYzYuTkwdl/kyZNAlDREzl06FDJzv6T4lL1+pDiKrRKZGNjgxdeeEHsGLWS+tYt7LlpxOR00i0rK8Pu3bvVn869vLwwfPhw9Yq0UiTHGTFyI8fZfwCQnp6OmJgYnDlzRl0kTJ48WbJFglRXoSVpcHR0xP79+7W2uTh16hQCAwNF+TuU/trOVOc2b96Mrl27wsLCAhYWFujWrRu+/PJLsWNV688//4SnpydCQ0Oxc+dObN++Ha+//jo6d+6M8+fPix1Pp5iYGPz3v//F0KFDsW3bNsTFxWHw4MEIDw/X2AOJHk1Nm1AWFhaKkKhm9+/fx+jRo2FjY4MtW7YgLS0N6enp2LJli2QLGwBo0qQJdu3aJXaMRqF///64ceOGVnthYaHW1ihSUbmHV1Wi7uElziQtEoscp6EOGTJEGDx4sFBQUKBuy8/PFwYPHiwMHTpUxGTV47TZhiHHKffW1tbC+fPnxY5hsFGjRglLly4VO4biqVQq4dq1a1rt165dE0xMTERIVLuRI0cK7du3F7755hshJydHyMnJEb755hvBxcVFCA0NFSUTL0s1MnKchtq0aVP88ssv6Nq1q0b78ePH4e/vL8kF8eQ6I0Zu5Dj7T4pL1etDiqvQKsmJEycAAD169EBCQgJatGihfqysrAx79+7FmjVrcPHiRZESVk+KW7ewuGlk5HjSbdGiBX744Qf4+flptKekpGDYsGGSnAou1xkxciPH2X9yLRIkuQqtghgZGanHP+o6LVtYWODTTz/FmDFjGjqa3qS0dQuLm0ZGjifd0NBQpKen44svvsCTTz4JAPj111/x5ptvwsfHBxs3bhQ3oA6cNkvVYZFAuly6dAmCIMDNzQ1Hjx6Fvb29+jFTU1O0atVK0hMopIbFTSMjx5PujRs38MYbb+D7779Xr/lQWlqK4cOHY+PGjbC2thY5oW5ymxEjd4KMZv8RUf1icdMIyfWkm5mZibNnz6ozV720JhWcNtuwOOW+/kh9FVqi6rC4aUR40m04NjY2SE9P58+5nsllp2q5FglSX4VWKVxdXR+qxzEiIkKyY7TExuKmkZHjSbesrAwbN27EgQMHkJeXh/Lyco3HpfimKtcZMXIjl9l/SigSYmJicPDgwWpXoZ08ebLICeUrKSnpoZ7n4uICZ2fnOk6jDCxuGhk5nnTHjx+PjRs34tlnn0WbNm20PuFIcVE8uc6IkRs5zv6Ta5EgxVVoiarD4qaRkeNJt2XLlti8eTOGDh0qdhS9cUZMw5Dj7D+5FglWVlb49ttvtVbJTUhIwIgRI8RbiVbBcnJyoFKp0K5dO7GjyA43zmxk1q1bBxsbG6SlpSEtLU3jMZVKJcnixtTUVLKDh6sjlcshSifHTSgrl6qvWtyIulS9HoKCgjB69GgsXboUPXv2BFCxYGJ0dLQsNnqUi9LSUsyZMwfLly9XL1DarFkzTJgwAbNmzdLaJZx0Y88NSd7SpUtx4cIFrFixgtN8SYvcZv+FhoYiKSlJZ5HQp08fbNq0SeSEuklxFVolCg8Px65duzB37lz1qttHjhzB7NmzMWLECKxevVrkhPLA4oYkLygoCImJiWjRogU6d+6s9cll586dIiXTJNcZMXIl19l/ci8SpLQKrRJZW1vjf//7H4YMGaLR/tNPP+GVV17BzZs3RUomLyxuGgG5n3RHjx5d4+MbNmxooCQ1U8KMGLmR4+y/SiwSSBcHBwccPHgQnp6eGu1nzpxBnz598Pfff4uUTF5Y3DQCPOk2PLnOiJEbOc7+I6rJ3LlzcfbsWWzYsAFmZmYAgOLiYoSFhaFDhw6YNWuWyAnlgcVNI8OTbsOQ64wYuZHj7D+imgQFBeHAgQMwMzND9+7dAQDHjx9HSUkJBgwYoHGsVC7JSxGLm0aGJ92GwWmzDYNT7klparsM/yCpXJKXIk4Fb2TkOg1VbjhttmFwyj0pDQuWusGem0ZGrtNQ5UbuM2KIiOSMxU0jw5Nuw+KMmLon99l/RDUpKCjABx98gMTERJ176V2/fl2kZPLC4qaRkttJ98CBA1i2bBnOnDkDlUqFTp06ISIiAgMHDhQ7GjUwzv4jJRsyZAjOnz+PsLAwODg4aC1c+sYbb4iUTF5Y3JDkrVixApGRkXjppZfUK3b+8ssv2L59O2JiYjB+/HiRE5JYOPuPlMbKygrJycnqmVL0cFjckOQ5Ojpi+vTpWkXMZ599hgULFnCGVyPG2X+kNE888QQ+/fRT9ZhIejhGYgcgqk1hYSEGDx6s1R4YGIjCwkIREpFUVM7+q4qz/0iuVq5ciRkzZiApKQkFBQUoLCzUuJF+WNyQ5A0fPhy7du3Sav/2228xbNgwERKRVFROud++fTv++usv/PXXX9i+fTvCwsI45Z5kycbGBjdv3kT//v3RqlUr2NrawtbWFjY2NupLr1Q7XpYiyZs/fz6WLFkCf39/jTE3KSkpmDx5Mpo3b64+livSNi6c/UdK8+STT8LExASTJk3SOaC4b9++IiWTFxY3JHk1rUL7IK5I23jJbfYfUXUsLS2RkZGhnv1HD4crFJPkcRVaqk3Tpk3RrVs3sWMQPTJfX1/k5OSwuHlE7LkhWan8da3aVUtEpATffPMNZs+ejejoaHTt2hVNmjTReJxFvH5Y3JAsbN68GYsXL0ZmZiYAoGPHjoiOjsbIkSNFTkZEVHeMjLTn+ahUKgiCAJVKhbKyMhFSyQ8vS5HkxcTEYObMmRg/fjz8/f0hCAJSUlIQHh6O/Px8REZGih2RiKhO8DJ83WDPDUmeq6sr5syZg9DQUI32TZs2Yfbs2XwzICLFOHToEPz8/GBiotn3UFpaitTUVPTp00ekZPLC4oYkz9zcHKdOnYK7u7tGe2ZmJrp27Yp79+6JlIyIqG4ZGxsjNzcXrVq10mgvKChAq1ateFlKT1zEjyTP3d0d27Zt02qPi4tDhw4dREhERFQ/KsfWVFVQUMAlDgzAMTckeXPmzEFwcDAOHToEf39/qFQqJCcn48CBAzqLHiIiualcUVulUmHUqFEwMzNTP1ZWVoYTJ07Az89PrHiyw+KGJO/FF1/E0aNHERMTg927d0MQBHh5eeHo0aPw9vYWOx4R0SOztrYGUNFzY2VlBQsLC/Vjpqam6NmzJ958802x4skOx9yQpN2/fx9vvfUWZs6cCTc3N7HjEBHVqzlz5mDKlCm8BPWIWNyQ5NnY2CA9PZ3FDRER6YUDiknygoKCsHv3brFjEBGRTHDMDUmeu7s75s2bh9TUVPj4+Gh113IncCIiehAvS5Hk1bQrOHcCJyKiqljcEBERkaJwzA0REZGEHDhwAM899xwee+wxuLu747nnnsPPP/8sdixZYc8NSVJUVJTex8bExNRjEiKihrNixQpERkbipZdeQq9evQAAv/zyC7Zv346YmBiMHz9e5ITywOKGJCkgIEDjflpaGsrKyuDh4QEAOHfuHIyNjeHj44OEhAQxIhIR1TlHR0dMnz5dq4j57LPPsGDBAly5ckWkZPLC2VIkSYmJiep/x8TEwMrKCps2bYKtrS0A4J9//sHo0aPRu3dvsSISEdW5wsJCDB48WKs9MDAQ7777rgiJ5Ik9NyR5jo6O2L9/Pzp37qzRfurUKQQGBvKTDBEpxmuvvYYePXogOjpao33JkiVIS0vD1q1bRUomL+y5IckrLCzEtWvXtIqbvLw83Lp1S6RURER1z9PTEwsWLMDBgwc1xtykpKRg8uTJWL58ufpYrvFVPfbckOSFhoYiKSkJS5cuRc+ePQFU/LFHR0ejT58+2LRpk8gJiYjqRk3rej2Ia3zVjMUNSV5RURGmTJmC9evX4/79+wAAExMThIWFYfHixdxgjoiINLC4Idm4c+cOzp8/D0EQ4O7uzqKGiBSt8vSsUqlETiI/XMSPZKNp06bo1q0bunfvzsKGiBRr8+bN6Nq1KywsLGBhYYFu3brhyy+/FDuWrHBAMRERkUTExMRg5syZGD9+PPz9/SEIAlJSUhAeHo78/HxERkaKHVEWeFmKiIhIIlxdXTFnzhyEhoZqtG/atAmzZ89GVlaWSMnkhZeliIiIJCI3Nxd+fn5a7X5+fsjNzRUhkTyxuCEiIpIId3d3bNu2Tas9Li4OHTp0ECGRPHHMDRERkUTMmTMHwcHBOHToEPz9/aFSqZCcnIwDBw7oLHpIN465ISIikpD09HTExMTgzJkzEAQBXl5emDx5Mry9vcWOJhssboiIiCTg/v37eOuttzBz5ky4ubmJHUfWOOaGiIhIApo0aYJdu3aJHUMRWNwQERFJRFBQEHbv3i12DNnjgGIiIiKJcHd3x7x585CamgofHx+t1di5E7h+OOaGiIhIImraFZw7geuPxQ0REREpCsfcEBERkaJwzA0REZGIoqKi9D42JiamHpMoB4sbIiIiEWVkZGjcT0tLQ1lZGTw8PAAA586dg7GxMXx8fMSIJ0ssboiIiESUmJio/ndMTAysrKywadMm2NraAgD++ecfjB49Gr179xYrouxwQDEREZFEODo6Yv/+/ejcubNG+6lTpxAYGIgrV66IlExeOKCYiIhIIgoLC3Ht2jWt9ry8PNy6dUuERPLE4oaIiEgigoKCMHr0aGzfvh1//fUX/vrrL2zfvh1hYWF44YUXxI4nG7wsRUREJBFFRUWYMmUK1q9fj/v37wMATExMEBYWhsWLF2utWEy6sbghIiKSmDt37uD8+fMQBAHu7u4sagzE4oaIiIgUhWNuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKP8Pcz2aJ+IGCEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_comparisons_data(simulation_comparisons_4, 's4_cCmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for different features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, drop_columns=features_weather, objective='Biome_Cmax', experiment_name='s4_with_Biome_dropWeather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, use_columns=features_weather, objective='Biome_Cmax', experiment_name='s4_with_Biome_useWeather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is quite decent performance though not as good as with biome_obs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.6\n",
    "\n",
    "Test the model trained with 'Biome_Cmax' on 'Biome_obs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, objective='Biome_Cmax', objective_test='Biome_obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who would have thought? The model performs as badly as an antigen test measuring temperature. Now test the model trained on 'Biome_obs' on 'Biome_Cmax' (and expect a similar result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_4, region_test_4, objective='Biome_obs', objective_test='Biome_Cmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the result is just as bad. What a surprise. Now compare our model with LPJ-Guess output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for objective in ['Biome_obs','Biome_Cmax']:\n",
    "    print(f'Comparing LPJ-Guess with our model for the parameter {objective}')\n",
    "    model_run(region_train_4, region_test_4, objective=objective, objective_test=f'LPJ_{objective}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who would have thought that our model works badly in this case (duh)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we creatively use the same test and validation set as in part 4. Though we swap order because of performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_train_5 = data_index_2['Pan_2007'] == 'Canada'\n",
    "region_test_5 = data_index_2['Pan_2007'] == 'Russia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "data1 = data_index_2.loc[region_train_5] \n",
    "data2 = data_index_2.loc[region_test_5]\n",
    "\n",
    "data = pd.concat([data1,data2])\n",
    "plot_statistics(data, name_data = 'Section5Canada_Russia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_5, region_test_5, objective='NPP', continuous_Y=True, feature_plots=False, experiment_name='s5_npp_basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty decent outcome. Let's see how it behaves with 'VegC'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(region_train_5, region_test_5, objective='VegC', continuous_Y=True, feature_plots=True, experiment_name='s5_vegc_basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'VegC' seems to perform worse. In the following we focus on NPP. What happens if we drop the medians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "performance = model_run(region_train_5, region_test_5, experiment_name='s5_basic', continuous_Y=True)\n",
    "simulation_comparisons_5 = pd.DataFrame([['base']+performance], columns=['experiment name', 'R^2 score, train', 'score, test',\n",
    "             'MSE, test', 'MSE sktfct, test', 'sqrt(MSE)', 'max err', 'mean abs err'])\n",
    "\n",
    "for i,feature_name in enumerate(features_names):\n",
    "    display(Markdown('---'))\n",
    "    print(f'Dropping season {feature_name}')\n",
    "    print(f'We dropped the features: {drop_features[i]}')\n",
    "    performance = model_run(region_train_5, region_test_5, continuous_Y=True, \\\n",
    "               drop_columns=drop_features[i], experiment_name=f's5_npp_drop_{feature_name.replace(\"|\",\"_\")}')\n",
    "    \n",
    "    simulation_comparisons_5 = pd.concat([simulation_comparisons_5, pd.DataFrame([[f'drop {feature_name}']+performance], columns=list(simulation_comparisons_5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_comparisons_5 = simulation_comparisons_5.reset_index(drop=True)\n",
    "simulation_comparisons_5.to_pickle('../data/simulation_comparisons_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(simulation_comparisons_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparisons_data_regr(simulation_comparisons, experiment_name=None):\n",
    "    simulation_comparisons['1-score, test']= 1-simulation_comparisons['score, test']\n",
    "    labels = ['1-score, test','MSE, test', 'MSE sktfct, test', 'max err', 'mean abs err']\n",
    "    ylabels = ['1-($R^2$ score)', 'MSE', 'MSE sktfct', 'Maximal error', 'Mean absolute error']\n",
    "    plt_names = ['1_R2score','MSE','MSE_sktfct','MaxErr','MeanAbsErr']\n",
    "    for i in range(len(labels)):\n",
    "        plt.subplots()\n",
    "        ax = sns.barplot(simulation_comparisons[['experiment name',labels[i]]], x='experiment name', y=labels[i])\n",
    "        ax.set_ylabel(ylabels[i])\n",
    "        ax.set_xlabel('')\n",
    "        plt.axhline(y=simulation_comparisons[labels[i]][0], color='blue',linestyle='--')\n",
    "        plt.xticks(rotation=90);\n",
    "        if experiment_name: save_plot(plt.gcf(), f'{experiment_name}_simulationComparisons_{plt_names[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparisons_data_regr(simulation_comparisons_5, 's5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_latex(simulation_comparisons_5.drop(columns=['R^2 score, train', 'MSE, test', 'MSE sktfct, test']), 's5_experiment_comparison')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
